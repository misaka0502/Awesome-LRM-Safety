[
  {
    "title": "Latent Diffusion Planning for Imitation Learning",
    "url": "http://arxiv.org/abs/2504.16925v1",
    "arxiv_id": "2504.16925v1",
    "authors": [
      "Amber Xie",
      "Oleh Rybkin",
      "Dorsa Sadigh",
      "Chelsea Finn"
    ],
    "published": "2025-04-23T17:53:34+00:00",
    "summary": "Recent progress in imitation learning has been enabled by policy architectures that scale to complex visuomotor tasks, multimodal distributions, and large datasets. However, these methods often rely on learning from large amount of expert demonstrations. To address these shortcomings, we propose Latent Diffusion Planning (LDP), a modular approach consisting of a planner which can leverage action-free demonstrations, and an inverse dynamics model which can leverage suboptimal data, that both operate over a learned latent space. First, we learn a compact latent space through a variational autoencoder, enabling effective forecasting of future states in image-based domains. Then, we train a planner and an inverse dynamics model with diffusion objectives. By separating planning from action prediction, LDP can benefit from the denser supervision signals of suboptimal and action-free data. On simulated visual robotic manipulation tasks, LDP outperforms state-of-the-art imitation learning approaches, as they cannot leverage such additional data."
  },
  {
    "title": "Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous Driving",
    "url": "http://arxiv.org/abs/2504.16923v1",
    "arxiv_id": "2504.16923v1",
    "authors": [
      "Jacob Levy",
      "Jason Gibson",
      "Bogdan Vlahov",
      "Erica Tevere",
      "Evangelos Theodorou",
      "David Fridovich-Keil",
      "Patrick Spieler"
    ],
    "published": "2025-04-23T17:51:36+00:00",
    "summary": "High-speed off-road autonomous driving presents unique challenges due to complex, evolving terrain characteristics and the difficulty of accurately modeling terrain-vehicle interactions. While dynamics models used in model-based control can be learned from real-world data, they often struggle to generalize to unseen terrain, making real-time adaptation essential. We propose a novel framework that combines a Kalman filter-based online adaptation scheme with meta-learned parameters to address these challenges. Offline meta-learning optimizes the basis functions along which adaptation occurs, as well as the adaptation parameters, while online adaptation dynamically adjusts the onboard dynamics model in real time for model-based control. We validate our approach through extensive experiments, including real-world testing on a full-scale autonomous off-road vehicle, demonstrating that our method outperforms baseline approaches in prediction accuracy, performance, and safety metrics, particularly in safety-critical scenarios. Our results underscore the effectiveness of meta-learned dynamics model adaptation, advancing the development of reliable autonomous systems capable of navigating diverse and unseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA"
  },
  {
    "title": "Zero-shot Sim-to-Real Transfer for Reinforcement Learning-based Visual Servoing of Soft Continuum Arms",
    "url": "http://arxiv.org/abs/2504.16916v1",
    "arxiv_id": "2504.16916v1",
    "authors": [
      "Hsin-Jung Yang",
      "Mahsa Khosravi",
      "Benjamin Walt",
      "Girish Krishnan",
      "Soumik Sarkar"
    ],
    "published": "2025-04-23T17:41:55+00:00",
    "summary": "Soft continuum arms (SCAs) soft and deformable nature presents challenges in modeling and control due to their infinite degrees of freedom and non-linear behavior. This work introduces a reinforcement learning (RL)-based framework for visual servoing tasks on SCAs with zero-shot sim-to-real transfer capabilities, demonstrated on a single section pneumatic manipulator capable of bending and twisting. The framework decouples kinematics from mechanical properties using an RL kinematic controller for motion planning and a local controller for actuation refinement, leveraging minimal sensing with visual feedback. Trained entirely in simulation, the RL controller achieved a 99.8% success rate. When deployed on hardware, it achieved a 67% success rate in zero-shot sim-to-real transfer, demonstrating robustness and adaptability. This approach offers a scalable solution for SCAs in 3D visual servoing, with potential for further refinement and expanded applications."
  },
  {
    "title": "MorphoNavi: Aerial-Ground Robot Navigation with Object Oriented Mapping in Digital Twin",
    "url": "http://arxiv.org/abs/2504.16914v1",
    "arxiv_id": "2504.16914v1",
    "authors": [
      "Sausar Karaf",
      "Mikhail Martynov",
      "Oleg Sautenkov",
      "Zhanibek Darush",
      "Dzmitry Tsetserukou"
    ],
    "published": "2025-04-23T17:41:12+00:00",
    "summary": "This paper presents a novel mapping approach for a universal aerial-ground robotic system utilizing a single monocular camera. The proposed system is capable of detecting a diverse range of objects and estimating their positions without requiring fine-tuning for specific environments. The system's performance was evaluated through a simulated search-and-rescue scenario, where the MorphoGear robot successfully located a robotic dog while an operator monitored the process. This work contributes to the development of intelligent, multimodal robotic systems capable of operating in unstructured environments."
  },
  {
    "title": "Learning Verifiable Control Policies Using Relaxed Verification",
    "url": "http://arxiv.org/abs/2504.16879v1",
    "arxiv_id": "2504.16879v1",
    "authors": [
      "Puja Chaudhury",
      "Alexander Estornell",
      "Michael Everett"
    ],
    "published": "2025-04-23T16:54:35+00:00",
    "summary": "To provide safety guarantees for learning-based control systems, recent work has developed formal verification methods to apply after training ends. However, if the trained policy does not meet the specifications, or there is conservatism in the verification algorithm, establishing these guarantees may not be possible. Instead, this work proposes to perform verification throughout training to ultimately aim for policies whose properties can be evaluated throughout runtime with lightweight, relaxed verification algorithms. The approach is to use differentiable reachability analysis and incorporate new components into the loss function. Numerical experiments on a quadrotor model and unicycle model highlight the ability of this approach to lead to learned control policies that satisfy desired reach-avoid and invariance specifications."
  },
  {
    "title": "TTRL: Test-Time Reinforcement Learning",
    "url": "http://arxiv.org/abs/2504.16084v1",
    "arxiv_id": "2504.16084v1",
    "authors": [
      "Yuxin Zuo",
      "Kaiyan Zhang",
      "Shang Qu",
      "Li Sheng",
      "Xuekai Zhu",
      "Biqing Qi",
      "Youbang Sun",
      "Ganqu Cui",
      "Ning Ding",
      "Bowen Zhou"
    ],
    "published": "2025-04-22T17:59:56+00:00",
    "summary": "This paper investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in Large Language Models (LLMs). The core challenge of the problem is reward estimation during inference while not having access to ground-truth information. While this setting appears elusive, we find that common practices in Test-Time Scaling (TTS), such as majority voting, yield surprisingly effective rewards suitable for driving RL training. In this work, we introduce Test-Time Reinforcement Learning (TTRL), a novel method for training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs by utilizing the priors in the pre-trained models. Our experiments demonstrate that TTRL consistently improves performance across a variety of tasks and models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by approximately 159% on the AIME 2024 with only unlabeled test data. Furthermore, although TTRL is only supervised by the Maj@N metric, TTRL has demonstrated performance to consistently surpass the upper limit of the initial model, and approach the performance of models trained directly on test data with ground-truth labels. Our experimental findings validate the general effectiveness of TTRL across various tasks, and highlight TTRL's potential for broader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL"
  },
  {
    "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities",
    "url": "http://arxiv.org/abs/2504.16078v1",
    "arxiv_id": "2504.16078v1",
    "authors": [
      "Thomas Schmied",
      "J\u00f6rg Bornschein",
      "Jordi Grau-Moya",
      "Markus Wulfmeier",
      "Razvan Pascanu"
    ],
    "published": "2025-04-22T17:57:14+00:00",
    "summary": "The success of Large Language Models (LLMs) has sparked interest in various agentic applications. A key hypothesis is that LLMs, leveraging common sense and Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently solve complex domains. However, LLM agents have been found to suffer from sub-optimal exploration and the knowing-doing gap, the inability to effectively act on knowledge present in the model. In this work, we systematically study why LLMs perform sub-optimally in decision-making scenarios. In particular, we closely examine three prevalent failure modes: greediness, frequency bias, and the knowing-doing gap. We propose mitigation of these shortcomings by fine-tuning via Reinforcement Learning (RL) on self-generated CoT rationales. Our experiments across multi-armed bandits, contextual bandits, and Tic-tac-toe, demonstrate that RL fine-tuning enhances the decision-making abilities of LLMs by increasing exploration and narrowing the knowing-doing gap. Finally, we study both classic exploration mechanisms, such as $\\epsilon$-greedy, and LLM-specific approaches, such as self-correction and self-consistency, to enable more effective fine-tuning of LLMs for decision-making."
  },
  {
    "title": "ForesightNav: Learning Scene Imagination for Efficient Exploration",
    "url": "http://arxiv.org/abs/2504.16062v1",
    "arxiv_id": "2504.16062v1",
    "authors": [
      "Hardik Shah",
      "Jiaxu Xing",
      "Nico Messikommer",
      "Boyang Sun",
      "Marc Pollefeys",
      "Davide Scaramuzza"
    ],
    "published": "2025-04-22T17:38:38+00:00",
    "summary": "Understanding how humans leverage prior knowledge to navigate unseen environments while making exploratory decisions is essential for developing autonomous robots with similar abilities. In this work, we propose ForesightNav, a novel exploration strategy inspired by human imagination and reasoning. Our approach equips robotic agents with the capability to predict contextual information, such as occupancy and semantic details, for unexplored regions. These predictions enable the robot to efficiently select meaningful long-term navigation goals, significantly enhancing exploration in unseen environments. We validate our imagination-based approach using the Structured3D dataset, demonstrating accurate occupancy prediction and superior performance in anticipating unseen scene geometry. Our experiments show that the imagination module improves exploration efficiency in unseen environments, achieving a 100% completion rate for PointNav and an SPL of 67% for ObjectNav on the Structured3D Validation split. These contributions demonstrate the power of imagination-driven reasoning for autonomous systems to enhance generalizable and efficient exploration."
  },
  {
    "title": "SAR4SLPs: An Asynchronous Survey of Speech-Language Pathologists' Perspectives on Socially Assistive Robots",
    "url": "http://arxiv.org/abs/2504.16055v1",
    "arxiv_id": "2504.16055v1",
    "authors": [
      "Denielle Oliva",
      "Abbie Olszewski",
      "David Feil-Seifer"
    ],
    "published": "2025-04-22T17:32:09+00:00",
    "summary": "Socially Assistive Robots (SARs) offer unique opportunities within speech language pathology (SLP) education and practice by supporting interactive interventions for children with communication disorders. This paper explores the implementation of SAR4SLPs (Socially Assistive Robots for Speech-Language Pathologists) to investigate aspects such as engagement, therapeutic strategy discipline, and consistent intervention support. We assessed the current application of technology to clinical and educational settings, especially with respect to how SLPs might use SAR in their therapeutic work. An asynchronous remote community (ARC) collaborated with a cohort of practicing SLPs to consider the feasibility, potential effectiveness, and anticipated challenges with implementing SARs in day-to-day interventions and as practice facilitators. We focus in particular on the expressive functionality of SARs, modeling a foundational strategy that SLPs employ across various intervention targets. This paper highlights clinician-driven insights and design implications for developing SARs that support specific treatment goals through collaborative and iterative design."
  },
  {
    "title": "$\u03c0_{0.5}$: a Vision-Language-Action Model with Open-World Generalization",
    "url": "http://arxiv.org/abs/2504.16054v1",
    "arxiv_id": "2504.16054v1",
    "authors": [
      "Physical Intelligence",
      "Kevin Black",
      "Noah Brown",
      "James Darpinian",
      "Karan Dhabalia",
      "Danny Driess",
      "Adnan Esmail",
      "Michael Equi",
      "Chelsea Finn",
      "Niccolo Fusai",
      "Manuel Y. Galliker",
      "Dibya Ghosh",
      "Lachy Groom",
      "Karol Hausman",
      "Brian Ichter",
      "Szymon Jakubczak",
      "Tim Jones",
      "Liyiming Ke",
      "Devin LeBlanc",
      "Sergey Levine",
      "Adrian Li-Bell",
      "Mohith Mothukuri",
      "Suraj Nair",
      "Karl Pertsch",
      "Allen Z. Ren",
      "Lucy Xiaoyang Shi",
      "Laura Smith",
      "Jost Tobias Springenberg",
      "Kyle Stachowicz",
      "James Tanner",
      "Quan Vuong",
      "Homer Walke",
      "Anna Walling",
      "Haohuan Wang",
      "Lili Yu",
      "Ury Zhilinsky"
    ],
    "published": "2025-04-22T17:31:29+00:00",
    "summary": "In order for robots to be useful, they must perform practically relevant tasks in the real world, outside of the lab. While vision-language-action (VLA) models have demonstrated impressive results for end-to-end robot control, it remains an open question how far such models can generalize in the wild. We describe $\\pi_{0.5}$, a new model based on $\\pi_{0}$ that uses co-training on heterogeneous tasks to enable broad generalization. $\\pi_{0.5}$\\ uses data from multiple robots, high-level semantic prediction, web data, and other sources to enable broadly generalizable real-world robotic manipulation. Our system uses a combination of co-training and hybrid multi-modal examples that combine image observations, language commands, object detections, semantic subtask prediction, and low-level actions. Our experiments show that this kind of knowledge transfer is essential for effective generalization, and we demonstrate for the first time that an end-to-end learning-enabled robotic system can perform long-horizon and dexterous manipulation skills, such as cleaning a kitchen or bedroom, in entirely new homes."
  },
  {
    "title": "VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models",
    "url": "http://arxiv.org/abs/2504.15279v1",
    "arxiv_id": "2504.15279v1",
    "authors": [
      "Weiye Xu",
      "Jiahao Wang",
      "Weiyun Wang",
      "Zhe Chen",
      "Wengang Zhou",
      "Aijun Yang",
      "Lewei Lu",
      "Houqiang Li",
      "Xiaohua Wang",
      "Xizhou Zhu",
      "Wenhai Wang",
      "Jifeng Dai",
      "Jinguo Zhu"
    ],
    "published": "2025-04-21T17:59:53+00:00",
    "summary": "Visual reasoning is a core component of human intelligence and a critical capability for advanced multimodal models. Yet current reasoning evaluations of multimodal large language models (MLLMs) often rely on text descriptions and allow language-based reasoning shortcuts, failing to measure genuine vision-centric reasoning. To address this, we introduce VisuLogic: a benchmark of 1,000 human-verified problems across six categories (e.g., quantitative shifts, spatial relations, attribute comparisons). These various types of questions can be evaluated to assess the visual reasoning capabilities of MLLMs from multiple perspectives. We evaluate leading MLLMs on this benchmark and analyze their results to identify common failure modes. Most models score below 30% accuracy-only slightly above the 25% random baseline and far below the 51.4% achieved by humans-revealing significant gaps in visual reasoning. Furthermore, we provide a supplementary training dataset and a reinforcement-learning baseline to support further progress."
  },
  {
    "title": "Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs",
    "url": "http://arxiv.org/abs/2504.15280v1",
    "arxiv_id": "2504.15280v1",
    "authors": [
      "Chun-Hsiao Yeh",
      "Chenyu Wang",
      "Shengbang Tong",
      "Ta-Ying Cheng",
      "Rouyu Wang",
      "Tianzhe Chu",
      "Yuexiang Zhai",
      "Yubei Chen",
      "Shenghua Gao",
      "Yi Ma"
    ],
    "published": "2025-04-21T17:59:53+00:00",
    "summary": "Multi-view understanding, the ability to reconcile visual information across diverse viewpoints for effective navigation, manipulation, and 3D scene comprehension, is a fundamental challenge in Multi-Modal Large Language Models (MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive advances in high-level reasoning and planning, they frequently fall short when confronted with multi-view geometric consistency and cross-view correspondence. To comprehensively evaluate the challenges of MLLMs in multi-view scene reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human carefully annotated multi-view question-answer pairs across 90 diverse real-world scenes. Our six tasks (counting, attribute identification, relative distance, relative direction, object manipulation, and camera pose estimation) specifically test model's geometric correspondence and the capacity to align information consistently across views. Our extensive experiments, benchmark on 27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and GPT-4o against human evaluators reveals a substantial performance gap, indicating that current MLLMs remain far from human-level proficiency. Through in-depth analysis, we show that MLLMs are particularly underperforming under two aspects: (1) cross-view correspondence for partially occluded views and (2) establishing the coarse camera poses. These findings highlight the necessity of domain-specific refinements or modules that embed stronger multi-view awareness. We believe that our All-Angles Bench offers valuable insights and contribute to bridging the gap between MLLMs and human-level multi-view understanding. The project and benchmark are publicly available at https://danielchyeh.github.io/All-Angles-Bench/."
  },
  {
    "title": "DRAWER: Digital Reconstruction and Articulation With Environment Realism",
    "url": "http://arxiv.org/abs/2504.15278v1",
    "arxiv_id": "2504.15278v1",
    "authors": [
      "Hongchi Xia",
      "Entong Su",
      "Marius Memmel",
      "Arhan Jain",
      "Raymond Yu",
      "Numfor Mbiziwo-Tiapo",
      "Ali Farhadi",
      "Abhishek Gupta",
      "Shenlong Wang",
      "Wei-Chiu Ma"
    ],
    "published": "2025-04-21T17:59:49+00:00",
    "summary": "Creating virtual digital replicas from real-world data unlocks significant potential across domains like gaming and robotics. In this paper, we present DRAWER, a novel framework that converts a video of a static indoor scene into a photorealistic and interactive digital environment. Our approach centers on two main contributions: (i) a reconstruction module based on a dual scene representation that reconstructs the scene with fine-grained geometric details, and (ii) an articulation module that identifies articulation types and hinge positions, reconstructs simulatable shapes and appearances and integrates them into the scene. The resulting virtual environment is photorealistic, interactive, and runs in real time, with compatibility for game engines and robotic simulation platforms. We demonstrate the potential of DRAWER by using it to automatically create an interactive game in Unreal Engine and to enable real-to-sim-to-real transfer for robotics applications."
  },
  {
    "title": "DRAWER: Digital Reconstruction and Articulation With Environment Realism",
    "url": "http://arxiv.org/abs/2504.15278v2",
    "arxiv_id": "2504.15278v2",
    "authors": [
      "Hongchi Xia",
      "Entong Su",
      "Marius Memmel",
      "Arhan Jain",
      "Raymond Yu",
      "Numfor Mbiziwo-Tiapo",
      "Ali Farhadi",
      "Abhishek Gupta",
      "Shenlong Wang",
      "Wei-Chiu Ma"
    ],
    "published": "2025-04-21T17:59:49+00:00",
    "summary": "Creating virtual digital replicas from real-world data unlocks significant potential across domains like gaming and robotics. In this paper, we present DRAWER, a novel framework that converts a video of a static indoor scene into a photorealistic and interactive digital environment. Our approach centers on two main contributions: (i) a reconstruction module based on a dual scene representation that reconstructs the scene with fine-grained geometric details, and (ii) an articulation module that identifies articulation types and hinge positions, reconstructs simulatable shapes and appearances and integrates them into the scene. The resulting virtual environment is photorealistic, interactive, and runs in real time, with compatibility for game engines and robotic simulation platforms. We demonstrate the potential of DRAWER by using it to automatically create an interactive game in Unreal Engine and to enable real-to-sim-to-real transfer for robotics applications."
  },
  {
    "title": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning",
    "url": "http://arxiv.org/abs/2504.15275v1",
    "arxiv_id": "2504.15275v1",
    "authors": [
      "Jie Cheng",
      "Ruixi Qiao",
      "Lijun Li",
      "Chao Guo",
      "Junle Wang",
      "Gang Xiong",
      "Yisheng Lv",
      "Fei-Yue Wang"
    ],
    "published": "2025-04-21T17:59:02+00:00",
    "summary": "Process reward models (PRMs) have proven effective for test-time scaling of Large Language Models (LLMs) on challenging reasoning tasks. However, reward hacking issues with PRMs limit their successful application in reinforcement fine-tuning. In this paper, we identify the main cause of PRM-induced reward hacking: the canonical summation-form credit assignment in reinforcement learning (RL), which defines the value as cumulative gamma-decayed future rewards, easily induces LLMs to hack steps with high rewards. To address this, we propose PURE: Process sUpervised Reinforcement lEarning. The key innovation of PURE is a min-form credit assignment that formulates the value function as the minimum of future rewards. This method significantly alleviates reward hacking by limiting the value function range and distributing advantages more reasonably. Through extensive experiments on 3 base models, we show that PRM-based approaches enabling min-form credit assignment achieve comparable reasoning performance to verifiable reward-based methods within only 30% steps. In contrast, the canonical sum-form credit assignment collapses training even at the beginning! Additionally, when we supplement PRM-based fine-tuning with just 10% verifiable rewards, we further alleviate reward hacking and produce the best fine-tuned model based on Qwen2.5-Math-7B in our experiments, achieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5 benchmarks. Moreover, we summarize the observed reward hacking cases and analyze the causes of training collapse. Code and models are available at https://github.com/CJReinforce/PURE."
  },
  {
    "title": "Interpretable Locomotion Prediction in Construction Using a Memory-Driven LLM Agent With Chain-of-Thought Reasoning",
    "url": "http://arxiv.org/abs/2504.15263v1",
    "arxiv_id": "2504.15263v1",
    "authors": [
      "Ehsan Ahmadi",
      "Chao Wang"
    ],
    "published": "2025-04-21T17:45:21+00:00",
    "summary": "Construction tasks are inherently unpredictable, with dynamic environments and safety-critical demands posing significant risks to workers. Exoskeletons offer potential assistance but falter without accurate intent recognition across diverse locomotion modes. This paper presents a locomotion prediction agent leveraging Large Language Models (LLMs) augmented with memory systems, aimed at improving exoskeleton assistance in such settings. Using multimodal inputs - spoken commands and visual data from smart glasses - the agent integrates a Perception Module, Short-Term Memory (STM), Long-Term Memory (LTM), and Refinement Module to predict locomotion modes effectively. Evaluation reveals a baseline weighted F1-score of 0.73 without memory, rising to 0.81 with STM, and reaching 0.90 with both STM and LTM, excelling with vague and safety-critical commands. Calibration metrics, including a Brier Score drop from 0.244 to 0.090 and ECE from 0.222 to 0.044, affirm improved reliability. This framework supports safer, high-level human-exoskeleton collaboration, with promise for adaptive assistive systems in dynamic industries."
  },
  {
    "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
    "url": "http://arxiv.org/abs/2504.13837v1",
    "arxiv_id": "2504.13837v1",
    "authors": [
      "Yang Yue",
      "Zhiqi Chen",
      "Rui Lu",
      "Andrew Zhao",
      "Zhaokai Wang",
      "Yang Yue",
      "Shiji Song",
      "Gao Huang"
    ],
    "published": "2025-04-18T17:59:56+00:00",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning capabilities of LLMs, particularly in mathematics and programming tasks. It is widely believed that RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed corresponding base models' capacity. In this study, however, we critically re-examines this assumption by measuring the pass@\\textit{k} metric with large values of \\textit{k} to explore the reasoning capability boundary of the models across a wide range of model families and benchmarks. Surprisingly, the RL does \\emph{not}, in fact, elicit fundamentally new reasoning patterns. While RL-trained models outperform their base models at smaller values of $k$ (\\eg, $k$=1), base models can achieve a comparable or even higher pass@$k$ score compared to their RL counterparts at large $k$ values. The reasoning paths generated by RL-trained models are already included in the base models' sampling distribution, suggesting that most reasoning abilities manifested in RL-trained models are already obtained by base models. Further analysis shows that RL training boosts the performance by biasing the model's output distribution toward paths that are more likely to yield rewards, therefore sampling correct responses more efficiently. But this also results in a narrower reasoning capability boundary compared to base models. Similar results are observed in visual reasoning tasks trained with RLVR. Moreover, we find that distillation can genuinely introduce new knowledge into the model, different from RLVR. These findings underscore a critical limitation of RLVR in advancing LLM reasoning abilities which requires us to fundamentally rethink the impact of RL training in reasoning LLMs and the need of a better paradigm. Project Page: https://limit-of-RLVR.github.io"
  },
  {
    "title": "Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning",
    "url": "http://arxiv.org/abs/2504.13818v1",
    "arxiv_id": "2504.13818v1",
    "authors": [
      "Yixuan Even Xu",
      "Yash Savani",
      "Fei Fang",
      "Zico Kolter"
    ],
    "published": "2025-04-18T17:49:55+00:00",
    "summary": "Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing reasoning capabilities in large language models, but faces a fundamental asymmetry in computation and memory requirements: inference is embarrassingly parallel with a minimal memory footprint, while policy updates require extensive synchronization and are memory-intensive. To address this asymmetry, we introduce PODS (Policy Optimization with Down-Sampling), a framework that strategically decouples these phases by generating numerous rollouts in parallel but updating only on an informative subset. Within this framework, we develop max-variance down-sampling, a theoretically motivated method that selects rollouts with maximally diverse reward signals. We prove that this approach has an efficient algorithmic solution, and empirically demonstrate that GRPO with PODS using max-variance down-sampling achieves superior performance over standard GRPO on the GSM8K benchmark."
  },
  {
    "title": "DiffOG: Differentiable Policy Trajectory Optimization with Generalizability",
    "url": "http://arxiv.org/abs/2504.13807v1",
    "arxiv_id": "2504.13807v1",
    "authors": [
      "Zhengtong Xu",
      "Zichen Miao",
      "Qiang Qiu",
      "Zhe Zhang",
      "Yu She"
    ],
    "published": "2025-04-18T17:20:27+00:00",
    "summary": "Imitation learning-based visuomotor policies excel at manipulation tasks but often produce suboptimal action trajectories compared to model-based methods. Directly mapping camera data to actions via neural networks can result in jerky motions and difficulties in meeting critical constraints, compromising safety and robustness in real-world deployment. For tasks that require high robustness or strict adherence to constraints, ensuring trajectory quality is crucial. However, the lack of interpretability in neural networks makes it challenging to generate constraint-compliant actions in a controlled manner. This paper introduces differentiable policy trajectory optimization with generalizability (DiffOG), a learning-based trajectory optimization framework designed to enhance visuomotor policies. By leveraging the proposed differentiable formulation of trajectory optimization with transformer, DiffOG seamlessly integrates policies with a generalizable optimization layer. Visuomotor policies enhanced by DiffOG generate smoother, constraint-compliant action trajectories in a more interpretable way. DiffOG exhibits strong generalization capabilities and high flexibility. We evaluated DiffOG across 11 simulated tasks and 2 real-world tasks. The results demonstrate that DiffOG significantly enhances the trajectory quality of visuomotor policies while having minimal impact on policy performance, outperforming trajectory processing baselines such as greedy constraint clipping and penalty-based trajectory optimization. Furthermore, DiffOG achieves superior performance compared to existing constrained visuomotor policy."
  },
  {
    "title": "Imitation Learning with Precisely Labeled Human Demonstrations",
    "url": "http://arxiv.org/abs/2504.13803v1",
    "arxiv_id": "2504.13803v1",
    "authors": [
      "Yilong Song"
    ],
    "published": "2025-04-18T17:12:00+00:00",
    "summary": "Within the imitation learning paradigm, training generalist robots requires large-scale datasets obtainable only through diverse curation. Due to the relative ease to collect, human demonstrations constitute a valuable addition when incorporated appropriately. However, existing methods utilizing human demonstrations face challenges in inferring precise actions, ameliorating embodiment gaps, and fusing with frontier generalist robot training pipelines. In this work, building on prior studies that demonstrate the viability of using hand-held grippers for efficient data collection, we leverage the user's control over the gripper's appearance--specifically by assigning it a unique, easily segmentable color--to enable simple and reliable application of the RANSAC and ICP registration method for precise end-effector pose estimation. We show in simulation that precisely labeled human demonstrations on their own allow policies to reach on average 88.1% of the performance of using robot demonstrations, and boost policy performance when combined with robot demonstrations, despite the inherent embodiment gap."
  },
  {
    "title": "Unified Manipulability and Compliance Analysis of Modular Soft-Rigid Hybrid Fingers",
    "url": "http://arxiv.org/abs/2504.13800v1",
    "arxiv_id": "2504.13800v1",
    "authors": [
      "Jianshu Zhou",
      "Boyuan Liang",
      "Junda Huang",
      "Masayoshi Tomizuka"
    ],
    "published": "2025-04-18T17:05:54+00:00",
    "summary": "This paper presents a unified framework to analyze the manipulability and compliance of modular soft-rigid hybrid robotic fingers. The approach applies to both hydraulic and pneumatic actuation systems. A Jacobian-based formulation maps actuator inputs to joint and task-space responses. Hydraulic actuators are modeled under incompressible assumptions, while pneumatic actuators are described using nonlinear pressure-volume relations. The framework enables consistent evaluation of manipulability ellipsoids and compliance matrices across actuation modes. We validate the analysis using two representative hands: DexCo (hydraulic) and Edgy-2 (pneumatic). Results highlight actuation-dependent trade-offs in dexterity and passive stiffness. These findings provide insights for structure-aware design and actuator selection in soft-rigid robotic fingers."
  },
  {
    "title": "ViTa-Zero: Zero-shot Visuotactile Object 6D Pose Estimation",
    "url": "http://arxiv.org/abs/2504.13179v1",
    "arxiv_id": "2504.13179v1",
    "authors": [
      "Hongyu Li",
      "James Akl",
      "Srinath Sridhar",
      "Tye Brady",
      "Taskin Padir"
    ],
    "published": "2025-04-17T17:59:56+00:00",
    "summary": "Object 6D pose estimation is a critical challenge in robotics, particularly for manipulation tasks. While prior research combining visual and tactile (visuotactile) information has shown promise, these approaches often struggle with generalization due to the limited availability of visuotactile data. In this paper, we introduce ViTa-Zero, a zero-shot visuotactile pose estimation framework. Our key innovation lies in leveraging a visual model as its backbone and performing feasibility checking and test-time optimization based on physical constraints derived from tactile and proprioceptive observations. Specifically, we model the gripper-object interaction as a spring-mass system, where tactile sensors induce attractive forces, and proprioception generates repulsive forces. We validate our framework through experiments on a real-world robot setup, demonstrating its effectiveness across representative visual backbones and manipulation scenarios, including grasping, object picking, and bimanual handover. Compared to the visual models, our approach overcomes some drastic failure modes while tracking the in-hand object pose. In our experiments, our approach shows an average increase of 55% in AUC of ADD-S and 60% in ADD, along with an 80% lower position error compared to FoundationPose."
  },
  {
    "title": "Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation",
    "url": "http://arxiv.org/abs/2504.13175v1",
    "arxiv_id": "2504.13175v1",
    "authors": [
      "Sizhe Yang",
      "Wenye Yu",
      "Jia Zeng",
      "Jun Lv",
      "Kerui Ren",
      "Cewu Lu",
      "Dahua Lin",
      "Jiangmiao Pang"
    ],
    "published": "2025-04-17T17:59:43+00:00",
    "summary": "Visuomotor policies learned from teleoperated demonstrations face challenges such as lengthy data collection, high costs, and limited data diversity. Existing approaches address these issues by augmenting image observations in RGB space or employing Real-to-Sim-to-Real pipelines based on physical simulators. However, the former is constrained to 2D data augmentation, while the latter suffers from imprecise physical simulation caused by inaccurate geometric reconstruction. This paper introduces RoboSplat, a novel method that generates diverse, visually realistic demonstrations by directly manipulating 3D Gaussians. Specifically, we reconstruct the scene through 3D Gaussian Splatting (3DGS), directly edit the reconstructed scene, and augment data across six types of generalization with five techniques: 3D Gaussian replacement for varying object types, scene appearance, and robot embodiments; equivariant transformations for different object poses; visual attribute editing for various lighting conditions; novel view synthesis for new camera perspectives; and 3D content generation for diverse object types. Comprehensive real-world experiments demonstrate that RoboSplat significantly enhances the generalization of visuomotor policies under diverse disturbances. Notably, while policies trained on hundreds of real-world demonstrations with additional 2D data augmentation achieve an average success rate of 57.2%, RoboSplat attains 87.8% in one-shot settings across six types of generalization in the real world."
  },
  {
    "title": "A New Semidefinite Relaxation for Linear and Piecewise-Affine Optimal Control with Time Scaling",
    "url": "http://arxiv.org/abs/2504.13170v1",
    "arxiv_id": "2504.13170v1",
    "authors": [
      "Lujie Yang",
      "Tobia Marcucci",
      "Pablo A. Parrilo",
      "Russ Tedrake"
    ],
    "published": "2025-04-17T17:59:23+00:00",
    "summary": "We introduce a semidefinite relaxation for optimal control of linear systems with time scaling. These problems are inherently nonconvex, since the system dynamics involves bilinear products between the discretization time step and the system state and controls. The proposed relaxation is closely related to the standard second-order semidefinite relaxation for quadratic constraints, but we carefully select a subset of the possible bilinear terms and apply a change of variables to achieve empirically tight relaxations while keeping the computational load light. We further extend our method to handle piecewise-affine (PWA) systems by formulating the PWA optimal-control problem as a shortest-path problem in a graph of convex sets (GCS). In this GCS, different paths represent different mode sequences for the PWA system, and the convex sets model the relaxed dynamics within each mode. By combining a tight convex relaxation of the GCS problem with our semidefinite relaxation with time scaling, we can solve PWA optimal-control problems through a single semidefinite program."
  },
  {
    "title": "Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling",
    "url": "http://arxiv.org/abs/2504.13169v1",
    "arxiv_id": "2504.13169v1",
    "authors": [
      "Tsung-Han Wu",
      "Heekyung Lee",
      "Jiaxin Ge",
      "Joseph E. Gonzalez",
      "Trevor Darrell",
      "David M. Chan"
    ],
    "published": "2025-04-17T17:59:22+00:00",
    "summary": "Vision-Language Models (VLMs) excel at visual understanding but often suffer from visual hallucinations, where they generate descriptions of nonexistent objects, actions, or concepts, posing significant risks in safety-critical applications. Existing hallucination mitigation methods typically follow one of two paradigms: generation adjustment, which modifies decoding behavior to align text with visual inputs, and post-hoc verification, where external models assess and correct outputs. While effective, generation adjustment methods often rely on heuristics and lack correction mechanisms, while post-hoc verification is complicated, typically requiring multiple models and tending to reject outputs rather than refine them. In this work, we introduce REVERSE, a unified framework that integrates hallucination-aware training with on-the-fly self-verification. By leveraging a new hallucination-verification dataset containing over 1.3M semi-synthetic samples, along with a novel inference-time retrospective resampling technique, our approach enables VLMs to both detect hallucinations during generation and dynamically revise those hallucinations. Our evaluations show that REVERSE achieves state-of-the-art hallucination reduction, outperforming the best existing methods by up to 12% on CHAIR-MSCOCO and 28% on HaloQuest. Our dataset, model, and code are available at: https://reverse-vlm.github.io."
  },
  {
    "title": "RUKA: Rethinking the Design of Humanoid Hands with Learning",
    "url": "http://arxiv.org/abs/2504.13165v1",
    "arxiv_id": "2504.13165v1",
    "authors": [
      "Anya Zorin",
      "Irmak Guzey",
      "Billy Yan",
      "Aadhithya Iyer",
      "Lisa Kondrich",
      "Nikhil X. Bhattasali",
      "Lerrel Pinto"
    ],
    "published": "2025-04-17T17:58:59+00:00",
    "summary": "Dexterous manipulation is a fundamental capability for robotic systems, yet progress has been limited by hardware trade-offs between precision, compactness, strength, and affordability. Existing control methods impose compromises on hand designs and applications. However, learning-based approaches present opportunities to rethink these trade-offs, particularly to address challenges with tendon-driven actuation and low-cost materials. This work presents RUKA, a tendon-driven humanoid hand that is compact, affordable, and capable. Made from 3D-printed parts and off-the-shelf components, RUKA has 5 fingers with 15 underactuated degrees of freedom enabling diverse human-like grasps. Its tendon-driven actuation allows powerful grasping in a compact, human-sized form factor. To address control challenges, we learn joint-to-actuator and fingertip-to-actuator models from motion-capture data collected by the MANUS glove, leveraging the hand's morphological accuracy. Extensive evaluations demonstrate RUKA's superior reachability, durability, and strength compared to other robotic hands. Teleoperation tasks further showcase RUKA's dexterous movements. The open-source design and assembly instructions of RUKA, code, and data are available at https://ruka-hand.github.io/."
  },
  {
    "title": "Adapting a World Model for Trajectory Following in a 3D Game",
    "url": "http://arxiv.org/abs/2504.12299v1",
    "arxiv_id": "2504.12299v1",
    "authors": [
      "Marko Tot",
      "Shu Ishida",
      "Abdelhak Lemkhenter",
      "David Bignell",
      "Pallavi Choudhury",
      "Chris Lovett",
      "Luis Fran\u00e7a",
      "Matheus Ribeiro Furtado de Mendon\u00e7a",
      "Tarun Gupta",
      "Darren Gehring",
      "Sam Devlin",
      "Sergio Valcarcel Macua",
      "Raluca Georgescu"
    ],
    "published": "2025-04-16T17:59:54+00:00",
    "summary": "Imitation learning is a powerful tool for training agents by leveraging expert knowledge, and being able to replicate a given trajectory is an integral part of it. In complex environments, like modern 3D video games, distribution shift and stochasticity necessitate robust approaches beyond simple action replay. In this study, we apply Inverse Dynamics Models (IDM) with different encoders and policy heads to trajectory following in a modern 3D video game -- Bleeding Edge. Additionally, we investigate several future alignment strategies that address the distribution shift caused by the aleatoric uncertainty and imperfections of the agent. We measure both the trajectory deviation distance and the first significant deviation point between the reference and the agent's trajectory and show that the optimal configuration depends on the chosen setting. Our results show that in a diverse data setting, a GPT-style policy head with an encoder trained from scratch performs the best, DINOv2 encoder with the GPT-style policy head gives the best results in the low data regime, and both GPT-style and MLP-style policy heads had comparable results when pre-trained on a diverse setting and fine-tuned for a specific behaviour setting."
  },
  {
    "title": "A complete theory of the Clifford commutant",
    "url": "http://arxiv.org/abs/2504.12263v1",
    "arxiv_id": "2504.12263v1",
    "authors": [
      "Lennart Bittel",
      "Jens Eisert",
      "Lorenzo Leone",
      "Antonio A. Mele",
      "Salvatore F. E. Oliviero"
    ],
    "published": "2025-04-16T17:21:34+00:00",
    "summary": "The Clifford group plays a central role in quantum information science. It is the building block for many error-correcting schemes and matches the first three moments of the Haar measure over the unitary group -a property that is essential for a broad range of quantum algorithms, with applications in pseudorandomness, learning theory, benchmarking, and entanglement distillation. At the heart of understanding many properties of the Clifford group lies the Clifford commutant: the set of operators that commute with $k$-fold tensor powers of Clifford unitaries. Previous understanding of this commutant has been limited to relatively small values of $k$, constrained by the number of qubits $n$. In this work, we develop a complete theory of the Clifford commutant. Our first result provides an explicit orthogonal basis for the commutant and computes its dimension for arbitrary $n$ and $k$. We also introduce an alternative and easy-to-manipulate basis formed by isotropic sums of Pauli operators. We show that this basis is generated by products of permutations -which generate the unitary group commutant- and at most three other operators. Additionally, we develop a graphical calculus allowing a diagrammatic manipulation of elements of this basis. These results enable a wealth of applications: among others, we characterize all measurable magic measures and identify optimal strategies for stabilizer property testing, whose success probability also offers an operational interpretation to stabilizer entropies. Finally, we show that these results also generalize to multi-qudit systems with prime local dimension."
  },
  {
    "title": "Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning",
    "url": "http://arxiv.org/abs/2504.12254v1",
    "arxiv_id": "2504.12254v1",
    "authors": [
      "Mahmoud Salhab",
      "Marwan Elghitany",
      "Shameed Sait",
      "Syed Sibghat Ullah",
      "Mohammad Abusheikh",
      "Hasan Abusheikh"
    ],
    "published": "2025-04-16T17:05:14+00:00",
    "summary": "Automatic speech recognition (ASR) is crucial for human-machine interaction in diverse applications like conversational agents, industrial robotics, call center automation, and automated subtitling. However, developing high-performance ASR models remains challenging, particularly for low-resource languages like Arabic, due to the scarcity of large, labeled speech datasets, which are costly and labor-intensive to produce. In this work, we employ weakly supervised learning to train an Arabic ASR model using the Conformer architecture. Our model is trained from scratch on 15,000 hours of weakly annotated speech data covering both Modern Standard Arabic (MSA) and Dialectal Arabic (DA), eliminating the need for costly manual transcriptions. Despite the absence of human-verified labels, our approach attains state-of-the-art (SOTA) performance, exceeding all previous efforts in the field of Arabic ASR on the standard benchmarks. By demonstrating the effectiveness of weak supervision as a scalable, cost-efficient alternative to traditional supervised approaches, paving the way for improved ASR systems in low resource settings."
  },
  {
    "title": "Exotic Quantum States in Spin-1 Bose-Einstein Condensate with Spin-Orbit Coupling in Concentric Annular Traps",
    "url": "http://arxiv.org/abs/2504.12247v1",
    "arxiv_id": "2504.12247v1",
    "authors": [
      "Yun Liu",
      "Zu-Jian Ying"
    ],
    "published": "2025-04-16T16:54:14+00:00",
    "summary": "We explore the exotic quantum states emerging in the ground state (GS) of a strongly-correlated spin-1 Bose-Einstein condensate confined in two-dimensional concentric annular traps with a spin-orbit coupling (SOC). In the antiferromagnetic case, the GS density manifests various patterns of distributions, including facial-makeup states, petal states, topological fissure states, multiple-half-ring states and property-distinguished vertical and horizonal stripe states. We notice a peculiar phenomenon of density-phase separation in the sense that the variations of density and phase tend to be independent. In ferromagnetic case, the GS exhibits a semi-circular or half-disk status of density embedded with vortices and anti-vortices. The spin distribution can self-arrange into an array of half-skyrmions and we also find a half-antiskyrmion fence separating vortex-antivortex pairs. Our study indicates that one can manipulate the emergence of exotic quantum states via the interplay of the SOC, interaction and potential geometry and the abundant state variations might also provide potential resources for quantum metrology."
  },
  {
    "title": "Branching Bisimulation Learning",
    "url": "http://arxiv.org/abs/2504.12246v1",
    "arxiv_id": "2504.12246v1",
    "authors": [
      "Alessandro Abate",
      "Mirco Giacobbe",
      "Christian Micheletti",
      "Yannik Schnitzer"
    ],
    "published": "2025-04-16T16:52:07+00:00",
    "summary": "We introduce a bisimulation learning algorithm for non-deterministic transition systems. We generalise bisimulation learning to systems with bounded branching and extend its applicability to model checking branching-time temporal logic, while previously it was limited to deterministic systems and model checking linear-time properties. Our method computes a finite stutter-insensitive bisimulation quotient of the system under analysis, represented as a decision tree. We adapt the proof rule for well-founded bisimulations to an iterative procedure that trains candidate decision trees from sample transitions of the system, and checks their validity over the entire transition relation using SMT solving. This results in a new technology for model checking CTL* without the next-time operator. Our technique is sound, entirely automated, and yields abstractions that are succinct and effective for formal verification and system diagnostics. We demonstrate the efficacy of our method on diverse benchmarks comprising concurrent software, communication protocols and robotic scenarios. Our method performs comparably to mature tools in the special case of LTL model checking, and outperforms the state of the art in CTL and CTL* model checking for systems with very large and countably infinite state space."
  },
  {
    "title": "DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning",
    "url": "http://arxiv.org/abs/2504.11456v1",
    "arxiv_id": "2504.11456v1",
    "authors": [
      "Zhiwei He",
      "Tian Liang",
      "Jiahao Xu",
      "Qiuzhi Liu",
      "Xingyu Chen",
      "Yue Wang",
      "Linfeng Song",
      "Dian Yu",
      "Zhenwen Liang",
      "Wenxuan Wang",
      "Zhuosheng Zhang",
      "Rui Wang",
      "Zhaopeng Tu",
      "Haitao Mi",
      "Dong Yu"
    ],
    "published": "2025-04-15T17:59:51+00:00",
    "summary": "The capacity for complex mathematical reasoning is a key benchmark for artificial intelligence. While reinforcement learning (RL) applied to LLMs shows promise, progress is significantly hindered by the lack of large-scale training data that is sufficiently challenging, possesses verifiable answer formats suitable for RL, and is free from contamination with evaluation benchmarks. To address these limitations, we introduce DeepMath-103K, a new, large-scale dataset comprising approximately 103K mathematical problems, specifically designed to train advanced reasoning models via RL. DeepMath-103K is curated through a rigorous pipeline involving source analysis, stringent decontamination against numerous benchmarks, and filtering for high difficulty (primarily Levels 5-9), significantly exceeding existing open resources in challenge. Each problem includes a verifiable final answer, enabling rule-based RL, and three distinct R1-generated solutions suitable for diverse training paradigms like supervised fine-tuning or distillation. Spanning a wide range of mathematical topics, DeepMath-103K promotes the development of generalizable reasoning. We demonstrate that models trained on DeepMath-103K achieve significant improvements on challenging mathematical benchmarks, validating its effectiveness. We release DeepMath-103K publicly to facilitate community progress in building more capable AI reasoning systems: https://github.com/zwhe99/DeepMath."
  },
  {
    "title": "A Clean Slate for Offline Reinforcement Learning",
    "url": "http://arxiv.org/abs/2504.11453v1",
    "arxiv_id": "2504.11453v1",
    "authors": [
      "Matthew Thomas Jackson",
      "Uljad Berdica",
      "Jarek Liesen",
      "Shimon Whiteson",
      "Jakob Nicolaus Foerster"
    ],
    "published": "2025-04-15T17:59:05+00:00",
    "summary": "Progress in offline reinforcement learning (RL) has been impeded by ambiguous problem definitions and entangled algorithmic designs, resulting in inconsistent implementations, insufficient ablations, and unfair evaluations. Although offline RL explicitly avoids environment interaction, prior methods frequently employ extensive, undocumented online evaluation for hyperparameter tuning, complicating method comparisons. Moreover, existing reference implementations differ significantly in boilerplate code, obscuring their core algorithmic contributions. We address these challenges by first introducing a rigorous taxonomy and a transparent evaluation protocol that explicitly quantifies online tuning budgets. To resolve opaque algorithmic design, we provide clean, minimalistic, single-file implementations of various model-free and model-based offline RL methods, significantly enhancing clarity and achieving substantial speed-ups. Leveraging these streamlined implementations, we propose Unifloral, a unified algorithm that encapsulates diverse prior approaches within a single, comprehensive hyperparameter space, enabling algorithm development in a shared hyperparameter space. Using Unifloral with our rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR (model-free) and MoBRAC (model-based) - which substantially outperform established baselines. Our implementation is publicly available at https://github.com/EmptyJackson/unifloral."
  },
  {
    "title": "HeatSense: Intelligent Thermal Anomaly Detection for Securing NoC-Enabled MPSoCs",
    "url": "http://arxiv.org/abs/2504.11421v1",
    "arxiv_id": "2504.11421v1",
    "authors": [
      "Mahdi Hasanzadeh",
      "Kasem Khalil",
      "Cynthia Sturton",
      "Ahmad Patooghy"
    ],
    "published": "2025-04-15T17:36:53+00:00",
    "summary": "Multi-Processor System-on-Chips (MPSoCs) are highly vulnerable to thermal attacks that manipulate dynamic thermal management systems. To counter this, we propose an adaptive real-time monitoring mechanism that detects abnormal thermal patterns in chip tiles. Our design space exploration helped identify key thermal features for an efficient anomaly detection module to be implemented at routers of network-enabled MPSoCs. To minimize hardware overhead, we employ weighted moving average (WMA) calculations and bit-shift operations, ensuring a lightweight yet effective implementation. By defining a spectrum of abnormal behaviors, our system successfully detects and mitigates malicious temperature fluctuations, reducing severe cases from 3.00{\\deg}C to 1.9{\\deg}C. The anomaly detection module achieves up to 82% of accuracy in detecting thermal attacks, which is only 10-15% less than top-performing machine learning (ML) models like Random Forest. However, our approach reduces hardware usage by up to 75% for logic resources and 100% for specialized resources, making it significantly more efficient than ML-based solutions. This method provides a practical, low-cost solution for resource-constrained environments, ensuring resilience against thermal attacks while maintaining system performance."
  },
  {
    "title": "Embodied World Models Emerge from Navigational Task in Open-Ended Environments",
    "url": "http://arxiv.org/abs/2504.11419v1",
    "arxiv_id": "2504.11419v1",
    "authors": [
      "Li Jin",
      "Liu Jia"
    ],
    "published": "2025-04-15T17:35:13+00:00",
    "summary": "Understanding how artificial systems can develop spatial awareness and reasoning has long been a challenge in AI research. Traditional models often rely on passive observation, but embodied cognition theory suggests that deeper understanding emerges from active interaction with the environment. This study investigates whether neural networks can autonomously internalize spatial concepts through interaction, focusing on planar navigation tasks. Using Gated Recurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we show that agents can learn to encode spatial properties like direction, distance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS) to model the agent-environment interaction as a closed dynamical system, revealing stable limit cycles that correspond to optimal navigation strategies. Ridge Representation allows us to map navigation paths into a fixed-dimensional behavioral space, enabling comparison with neural states. Canonical Correlation Analysis (CCA) confirms strong alignment between these representations, suggesting that the agent's neural states actively encode spatial knowledge. Intervention experiments further show that specific neural dimensions are causally linked to navigation performance. This work provides an approach to bridging the gap between action and perception in AI, offering new insights into building adaptive, interpretable models that can generalize across complex environments. The causal validation of neural representations also opens new avenues for understanding and controlling the internal mechanisms of AI systems, pushing the boundaries of how machines learn and reason in dynamic, real-world scenarios."
  },
  {
    "title": "A tutorial on simulating nonlinear behaviors of flexible structures with the discrete differential geometry (DDG) method",
    "url": "http://arxiv.org/abs/2504.11417v1",
    "arxiv_id": "2504.11417v1",
    "authors": [
      "Weicheng Huang",
      "Zhuonan Hao",
      "Jiahao Li",
      "Dezhong Tong",
      "Kexin Guo",
      "Yingchao Zhang",
      "Huajian Gao",
      "K. Jimmy Hsia",
      "Mingchao Liu"
    ],
    "published": "2025-04-15T17:33:06+00:00",
    "summary": "Flexible elastic structures, such as beams, rods, ribbons, plates, and shells, exhibit complex nonlinear dynamical behaviors that are central to a wide range of engineering and scientific applications, including soft robotics, deployable structures, and biomedical devices. While various numerical methods have been developed to simulate these behaviors, many conventional approaches struggle to simultaneously capture geometric and material nonlinearities, as well as nonlinear external interactions, particularly in highly deformable and dynamically evolving systems. The Discrete Differential Geometry (DDG) method has emerged as a robust and efficient numerical framework that intrinsically preserves geometric properties, accommodates material nonlinearity, and accurately models interactions with external environments and fields. By directly discretizing geometric and mechanical quantities, DDG provides an accurate, stable, and efficient approach to modeling flexible structures, addressing key limitations of traditional numerical methods. This tutorial provides a systematic introduction to the DDG method for simulating nonlinear behaviors in flexible structures. It covers DDG theory, simulation frameworks, and MATLAB implementation, with examples spanning dynamic systems, geometric and material nonlinearities, and external interactions like magnetics and fluids, culminating in practical insights and future directions. By offering a comprehensive and practical guide, together with open-source MATLAB code, this tutorial aims to facilitate the broader adoption of DDG-based numerical tools among researchers and engineers in computational mechanics, applied mathematics, and structural design."
  },
  {
    "title": "Decoupled Diffusion Sparks Adaptive Scene Generation",
    "url": "http://arxiv.org/abs/2504.10485v1",
    "arxiv_id": "2504.10485v1",
    "authors": [
      "Yunsong Zhou",
      "Naisheng Ye",
      "William Ljungbergh",
      "Tianyu Li",
      "Jiazhi Yang",
      "Zetong Yang",
      "Hongzi Zhu",
      "Christoffer Petersson",
      "Hongyang Li"
    ],
    "published": "2025-04-14T17:59:57+00:00",
    "summary": "Controllable scene generation could reduce the cost of diverse data collection substantially for autonomous driving. Prior works formulate the traffic layout generation as predictive progress, either by denoising entire sequences at once or by iteratively predicting the next frame. However, full sequence denoising hinders online reaction, while the latter's short-sighted next-frame prediction lacks precise goal-state guidance. Further, the learned model struggles to generate complex or challenging scenarios due to a large number of safe and ordinal driving behaviors from open datasets. To overcome these, we introduce Nexus, a decoupled scene generation framework that improves reactivity and goal conditioning by simulating both ordinal and challenging scenarios from fine-grained tokens with independent noise states. At the core of the decoupled pipeline is the integration of a partial noise-masking training strategy and a noise-aware schedule that ensures timely environmental updates throughout the denoising process. To complement challenging scenario generation, we collect a dataset consisting of complex corner cases. It covers 540 hours of simulated data, including high-risk interactions such as cut-in, sudden braking, and collision. Nexus achieves superior generation realism while preserving reactivity and goal orientation, with a 40% reduction in displacement error. We further demonstrate that Nexus improves closed-loop planning by 20% through data augmentation and showcase its capability in safety-critical data generation."
  },
  {
    "title": "Weight Ensembling Improves Reasoning in Language Models",
    "url": "http://arxiv.org/abs/2504.10478v1",
    "arxiv_id": "2504.10478v1",
    "authors": [
      "Xingyu Dang",
      "Christina Baek",
      "Kaiyue Wen",
      "Zico Kolter",
      "Aditi Raghunathan"
    ],
    "published": "2025-04-14T17:59:07+00:00",
    "summary": "We investigate a failure mode that arises during the training of reasoning models, where the diversity of generations begins to collapse, leading to suboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during supervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a simple intervention of interpolating the weights of the latest SFT checkpoint with an early checkpoint, otherwise known as WiSE-FT, almost completely recovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves better test-time scaling (Best@k, majority vote) and achieves superior results with less data when tuned further by reinforcement learning. Finally, we find that WiSE-FT provides complementary performance gains that cannot be achieved only through diversity-inducing decoding strategies, like temperature scaling. We formalize a bias-variance tradeoff of Pass@k with respect to the expectation and variance of Pass@1 over the test distribution. We find that WiSE-FT can reduce bias and variance simultaneously, while temperature scaling inherently trades-off between bias and variance."
  },
  {
    "title": "Weight Ensembling Improves Reasoning in Language Models",
    "url": "http://arxiv.org/abs/2504.10478v2",
    "arxiv_id": "2504.10478v2",
    "authors": [
      "Xingyu Dang",
      "Christina Baek",
      "Kaiyue Wen",
      "Zico Kolter",
      "Aditi Raghunathan"
    ],
    "published": "2025-04-14T17:59:07+00:00",
    "summary": "We investigate a failure mode that arises during the training of reasoning models, where the diversity of generations begins to collapse, leading to suboptimal test-time scaling. Notably, the Pass@1 rate reliably improves during supervised finetuning (SFT), but Pass@k rapidly deteriorates. Surprisingly, a simple intervention of interpolating the weights of the latest SFT checkpoint with an early checkpoint, otherwise known as WiSE-FT, almost completely recovers Pass@k while also improving Pass@1. The WiSE-FT variant achieves better test-time scaling (Best@k, majority vote) and achieves superior results with less data when tuned further by reinforcement learning. Finally, we find that WiSE-FT provides complementary performance gains that cannot be achieved only through diversity-inducing decoding strategies, like temperature scaling. We formalize a bias-variance tradeoff of Pass@k with respect to the expectation and variance of Pass@1 over the test distribution. We find that WiSE-FT can reduce bias and variance simultaneously, while temperature scaling inherently trades-off between bias and variance."
  },
  {
    "title": "Co-optimizing Physical Reconfiguration Parameters and Controllers for an Origami-inspired Reconfigurable Manipulator",
    "url": "http://arxiv.org/abs/2504.10474v1",
    "arxiv_id": "2504.10474v1",
    "authors": [
      "Zhe Chen",
      "Li Chen",
      "Hao Zhang",
      "Jianguo Zhao"
    ],
    "published": "2025-04-14T17:56:38+00:00",
    "summary": "Reconfigurable robots that can change their physical configuration post-fabrication have demonstrate their potential in adapting to different environments or tasks. However, it is challenging to determine how to optimally adjust reconfigurable parameters for a given task, especially when the controller depends on the robot's configuration. In this paper, we address this problem using a tendon-driven reconfigurable manipulator composed of multiple serially connected origami-inspired modules as an example. Under tendon actuation, these modules can achieve different shapes and motions, governed by joint stiffnesses (reconfiguration parameters) and the tendon displacements (control inputs). We leverage recent advances in co-optimization of design and control for robotic system to treat reconfiguration parameters as design variables and optimize them using reinforcement learning techniques. We first establish a forward model based on the minimum potential energy method to predict the shape of the manipulator under tendon actuations. Using the forward model as the environment dynamics, we then co-optimize the control policy (on the tendon displacements) and joint stiffnesses of the modules for goal reaching tasks while ensuring collision avoidance. Through co-optimization, we obtain optimized joint stiffness and the corresponding optimal control policy to enable the manipulator to accomplish the task that would be infeasible with fixed reconfiguration parameters (i.e., fixed joint stiffness). We envision the co-optimization framework can be extended to other reconfigurable robotic systems, enabling them to optimally adapt their configuration and behavior for diverse tasks and environments."
  },
  {
    "title": "GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents",
    "url": "http://arxiv.org/abs/2504.10458v1",
    "arxiv_id": "2504.10458v1",
    "authors": [
      "Xiaobo Xia",
      "Run Luo"
    ],
    "published": "2025-04-14T17:45:54+00:00",
    "summary": "Existing efforts in building Graphical User Interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning on Large Vision-Language Models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose \\name, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and employing policy optimization algorithms such as Group Relative Policy Optimization (GRPO) to update the model, \\name achieves superior performance using only 0.02\\% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks."
  },
  {
    "title": "GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents",
    "url": "http://arxiv.org/abs/2504.10458v2",
    "arxiv_id": "2504.10458v2",
    "authors": [
      "Xiaobo Xia",
      "Run Luo"
    ],
    "published": "2025-04-14T17:45:54+00:00",
    "summary": "Existing efforts in building Graphical User Interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning on Large Vision-Language Models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose \\name, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and employing policy optimization algorithms such as Group Relative Policy Optimization (GRPO) to update the model, \\name achieves superior performance using only 0.02\\% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks."
  },
  {
    "title": "Anchor Token Matching: Implicit Structure Locking for Training-free AR Image Editing",
    "url": "http://arxiv.org/abs/2504.10434v1",
    "arxiv_id": "2504.10434v1",
    "authors": [
      "Taihang Hu",
      "Linxuan Li",
      "Kai Wang",
      "Yaxing Wang",
      "Jian Yang",
      "Ming-Ming Cheng"
    ],
    "published": "2025-04-14T17:25:19+00:00",
    "summary": "Text-to-image generation has seen groundbreaking advancements with diffusion models, enabling high-fidelity synthesis and precise image editing through cross-attention manipulation. Recently, autoregressive (AR) models have re-emerged as powerful alternatives, leveraging next-token generation to match diffusion models. However, existing editing techniques designed for diffusion models fail to translate directly to AR models due to fundamental differences in structural control. Specifically, AR models suffer from spatial poverty of attention maps and sequential accumulation of structural errors during image editing, which disrupt object layouts and global consistency. In this work, we introduce Implicit Structure Locking (ISLock), the first training-free editing strategy for AR visual models. Rather than relying on explicit attention manipulation or fine-tuning, ISLock preserves structural blueprints by dynamically aligning self-attention patterns with reference images through the Anchor Token Matching (ATM) protocol. By implicitly enforcing structural consistency in latent space, our method ISLock enables structure-aware editing while maintaining generative autonomy. Extensive experiments demonstrate that ISLock achieves high-quality, structure-consistent edits without additional training and is superior or comparable to conventional editing techniques. Our findings pioneer the way for efficient and flexible AR-based image editing, further bridging the performance gap between diffusion and autoregressive generative models. The code will be publicly available at https://github.com/hutaiHang/ATM"
  },
  {
    "title": "BiFlex: A Passive Bimodal Stiffness Flexible Wrist for Manipulation in Unstructured Environments",
    "url": "http://arxiv.org/abs/2504.08706v1",
    "arxiv_id": "2504.08706v1",
    "authors": [
      "Gu-Cheol Jeong",
      "Stefano Dalla Gasperina",
      "Ashish D. Deshpande",
      "Lillian Chin",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "published": "2025-04-11T17:16:13+00:00",
    "summary": "Robotic manipulation in unstructured, humancentric environments poses a dual challenge: achieving the precision need for delicate free-space operation while ensuring safety during unexpected contact events. Traditional wrists struggle to balance these demands, often relying on complex control schemes or complicated mechanical designs to mitigate potential damage from force overload. In response, we present BiFlex, a flexible robotic wrist that uses a soft buckling honeycomb structure to provides a natural bimodal stiffness response. The higher stiffness mode enables precise household object manipulation, while the lower stiffness mode provides the compliance needed to adapt to external forces. We design BiFlex to maintain a fingertip deflection of less than 1 cm while supporting loads up to 500g and create a BiFlex wrist for many grippers, including Panda, Robotiq, and BaRiFlex. We validate BiFlex under several real-world experimental evaluations, including surface wiping, precise pick-and-place, and grasping under environmental constraints. We demonstrate that BiFlex simplifies control while maintaining precise object manipulation and enhanced safety in real-world applications."
  },
  {
    "title": "Offline Reinforcement Learning using Human-Aligned Reward Labeling for Autonomous Emergency Braking in Occluded Pedestrian Crossing",
    "url": "http://arxiv.org/abs/2504.08704v1",
    "arxiv_id": "2504.08704v1",
    "authors": [
      "Vinal Asodia",
      "Zhenhua Feng",
      "Saber Fallah"
    ],
    "published": "2025-04-11T17:11:21+00:00",
    "summary": "Effective leveraging of real-world driving datasets is crucial for enhancing the training of autonomous driving systems. While Offline Reinforcement Learning enables the training of autonomous vehicles using such data, most available datasets lack meaningful reward labels. Reward labeling is essential as it provides feedback for the learning algorithm to distinguish between desirable and undesirable behaviors, thereby improving policy performance. This paper presents a novel pipeline for generating human-aligned reward labels. The proposed approach addresses the challenge of absent reward signals in real-world datasets by generating labels that reflect human judgment and safety considerations. The pipeline incorporates an adaptive safety component, activated by analyzing semantic segmentation maps, allowing the autonomous vehicle to prioritize safety over efficiency in potential collision scenarios. The proposed pipeline is applied to an occluded pedestrian crossing scenario with varying levels of pedestrian traffic, using synthetic and simulation data. The results indicate that the generated reward labels closely match the simulation reward labels. When used to train the driving policy using Behavior Proximal Policy Optimisation, the results are competitive with other baselines. This demonstrates the effectiveness of our method in producing reliable and human-aligned reward signals, facilitating the training of autonomous driving systems through Reinforcement Learning outside of simulation environments and in alignment with human values."
  },
  {
    "title": "Preparation and coherent manipulation of toroidal moments in molecules",
    "url": "http://arxiv.org/abs/2504.08701v1",
    "arxiv_id": "2504.08701v1",
    "authors": [
      "Kieran Hymas",
      "Alessandro Soncini"
    ],
    "published": "2025-04-11T17:07:23+00:00",
    "summary": "Molecules with an odd number of electrons are expected to display paramagnetic behaviour in a uniform magnetic field. Instead, a vanishing magnetization is often measured in a family of lanthanide complexes known as Single Molecule Toroics. The anomaly can be explained in terms of degenerate quantum states in which electron spins and orbital currents give rise to time-odd and space-odd magnetic vortices known as toroidal moments, carrying a vanishing magnetic dipole. Resilient to stray magnetic fields and susceptible to electric manipulation, toroidal moments are sparking growing interest for applications in spintronics, magnonics, and photonics. While macroscopic toroidal moments have been observed in extended systems such as bulk low-dimensional non-collinear ferromagnets, theoretically predicted quantum toroidal states in molecules are yet to be observed, as it is currently unclear how to split degenerate states carrying counter-rotating vortices via existing experimental setups. Here we propose a realistic experimental protocol to polarize and observe molecular toroidal moments using pulsed microwave radiation. Modelling the spin-dynamics in a pulsed MW-field, we find that three resonant MW-pulses, delivered either sequentially or simultaneously, to a class of MDy$_6$ (M = Al$^{3+}$, Cr$^{3+}$) molecules consisting of coupled Dy$_3$ toroidal moieties, can selectively and coherently transfer population to a long-lived polarized toroidal state. The ensuing magneto-electric properties can then be used as a read-out mechanism. Our results provide a strategy to measure and coherently manipulate toroidal states in molecular systems, which is expected to trigger applications of molecular toroidal states to quantum technologies."
  },
  {
    "title": "Performance Evaluation of Trajectory Tracking Controllers for a Quadruped Robot Leg",
    "url": "http://arxiv.org/abs/2504.08698v1",
    "arxiv_id": "2504.08698v1",
    "authors": [
      "Hossein Shojaei",
      "Hamid Rahmanei",
      "Seyed Hossein Sadati"
    ],
    "published": "2025-04-11T17:04:53+00:00",
    "summary": "The complexities in the dynamic model of the legged robots make it necessary to utilize model-free controllers in the task of trajectory tracking. In This paper, an adaptive transpose Jacobian approach is proposed to deal with the dynamic model complexity, which utilizes an adaptive PI-algorithm to adjust the control gains. The performance of the proposed control algorithm is compared with the conventional transpose Jacobian and sliding mode control algorithms and evaluated by the root mean square of the errors and control input energy criteria. In order to appraise the effectiveness of the proposed control system, simulations are carried out in MATLAB/Simulink software for a quadruped robot leg for semi-elliptical path tracking. The obtained results show that the proposed adaptive transpose Jacobian reduces the overshoot and root mean square of the errors and at the same time, decreases the control input energy. Moreover, transpose Jacobin and adaptive transpose Jacobian are more robust to changes in initial conditions compared to the conventional sliding mode control. Furthermore, sliding mode control performs well up to 20% uncertainties in the parameters due to its model-based nature, whereas the transpose Jacobin and the proposed adaptive transpose Jacobian algorithms show promising results even in higher mass uncertainties."
  },
  {
    "title": "Pobogot -- An Open-Hardware Open-Source Low Cost Robot for Swarm Robotics",
    "url": "http://arxiv.org/abs/2504.08686v1",
    "arxiv_id": "2504.08686v1",
    "authors": [
      "Alessia Loi",
      "Loona Macabre",
      "J\u00e9r\u00e9my Fersula",
      "Keivan Amini",
      "Leo Cazenille",
      "Fabien Caura",
      "Alexandre Guerre",
      "St\u00e9phane Gourichon",
      "Olivier Dauchot",
      "Nicolas Bredeche"
    ],
    "published": "2025-04-11T16:47:59+00:00",
    "summary": "This paper describes the Pogobot, an open-source and open-hardware platform specifically designed for research involving swarm robotics. Pogobot features vibration-based locomotion, infrared communication, and an array of sensors in a cost-effective package (approx. 250~euros/unit). The platform's modular design, comprehensive API, and extensible architecture facilitate the implementation of swarm intelligence algorithms and distributed online reinforcement learning algorithms. Pogobots offer an accessible alternative to existing platforms while providing advanced capabilities including directional communication between units. More than 200 Pogobots are already being used on a daily basis at Sorbonne Universit\\'e and PSL to study self-organizing systems, programmable active matter, discrete reaction-diffusion-advection systems as well as models of social learning and evolution."
  },
  {
    "title": "Perception-R1: Pioneering Perception Policy with Reinforcement Learning",
    "url": "http://arxiv.org/abs/2504.07954v1",
    "arxiv_id": "2504.07954v1",
    "authors": [
      "En Yu",
      "Kangheng Lin",
      "Liang Zhao",
      "Jisheng Yin",
      "Yana Wei",
      "Yuang Peng",
      "Haoran Wei",
      "Jianjian Sun",
      "Chunrui Han",
      "Zheng Ge",
      "Xiangyu Zhang",
      "Daxin Jiang",
      "Jingyu Wang",
      "Wenbing Tao"
    ],
    "published": "2025-04-10T17:58:27+00:00",
    "summary": "Inspired by the success of DeepSeek-R1, we explore the potential of rule-based reinforcement learning (RL) in MLLM post-training for perception policy learning. While promising, our initial experiments reveal that incorporating a thinking process through RL does not consistently lead to performance gains across all visual perception tasks. This leads us to delve into the essential role of RL in the context of visual perception. In this work, we return to the fundamentals and explore the effects of RL on different perception tasks. We observe that the perceptual complexity is a major factor in determining the effectiveness of RL. We also observe that reward design plays a crucial role in further approching the upper limit of model perception. To leverage these findings, we propose Perception-R1, a scalable RL framework using GRPO during MLLM post-training. With a standard Qwen2.5-VL-3B-Instruct, Perception-R1 achieves +4.2% on RefCOCO+, +17.9% on PixMo-Count, +4.2% on PageOCR, and notably, 31.9% AP on COCO2017 val for the first time, establishing a strong baseline for perception policy learning."
  },
  {
    "title": "Echo: An Open-Source, Low-Cost Teleoperation System with Force Feedback for Dataset Collection in Robot Learning",
    "url": "http://arxiv.org/abs/2504.07939v1",
    "arxiv_id": "2504.07939v1",
    "authors": [
      "Artem Bazhenov",
      "Sergei Satsevich",
      "Sergei Egorov",
      "Farit Khabibullin",
      "Dzmitry Tsetserukou"
    ],
    "published": "2025-04-10T17:51:37+00:00",
    "summary": "In this article, we propose Echo, a novel joint-matching teleoperation system designed to enhance the collection of datasets for manual and bimanual tasks. Our system is specifically tailored for controlling the UR manipulator and features a custom controller with force feedback and adjustable sensitivity modes, enabling precise and intuitive operation. Additionally, Echo integrates a user-friendly dataset recording interface, simplifying the process of collecting high-quality training data for imitation learning. The system is designed to be reliable, cost-effective, and easily reproducible, making it an accessible tool for researchers, laboratories, and startups passionate about advancing robotics through imitation learning. Although the current implementation focuses on the UR manipulator, Echo architecture is reconfigurable and can be adapted to other manipulators and humanoid systems. We demonstrate the effectiveness of Echo through a series of experiments, showcasing its ability to perform complex bimanual tasks and its potential to accelerate research in the field. We provide assembly instructions, a hardware description, and code at https://eterwait.github.io/Echo/."
  },
  {
    "title": "Echo Chamber: RL Post-training Amplifies Behaviors Learned in Pretraining",
    "url": "http://arxiv.org/abs/2504.07912v1",
    "arxiv_id": "2504.07912v1",
    "authors": [
      "Rosie Zhao",
      "Alexandru Meterez",
      "Sham Kakade",
      "Cengiz Pehlevan",
      "Samy Jelassi",
      "Eran Malach"
    ],
    "published": "2025-04-10T17:15:53+00:00",
    "summary": "Reinforcement learning (RL)-based fine-tuning has become a crucial step in post-training language models for advanced mathematical reasoning and coding. Following the success of frontier reasoning models, recent work has demonstrated that RL fine-tuning consistently improves performance, even in smaller-scale models; however, the underlying mechanisms driving these improvements are not well-understood. Understanding the effects of RL fine-tuning requires disentangling its interaction with pretraining data composition, hyperparameters, and model scale, but such problems are exacerbated by the lack of transparency regarding the training data used in many existing models. In this work, we present a systematic end-to-end study of RL fine-tuning for mathematical reasoning by training models entirely from scratch on different mixtures of fully open datasets. We investigate the effects of various RL fine-tuning algorithms (PPO, GRPO, and Expert Iteration) across models of different scales. Our study reveals that RL algorithms consistently converge towards a dominant output distribution, amplifying patterns in the pretraining data. We also find that models of different scales trained on the same data mixture will converge to distinct output distributions, suggesting that there are scale-dependent biases in model generalization. Moreover, we find that RL post-training on simpler questions can lead to performance gains on harder ones, indicating that certain reasoning capabilities generalize across tasks. Our findings show that small-scale proxies in controlled settings can elicit interesting insights regarding the role of RL in shaping language model behavior."
  },
  {
    "title": "Fast Adaptation with Behavioral Foundation Models",
    "url": "http://arxiv.org/abs/2504.07896v1",
    "arxiv_id": "2504.07896v1",
    "authors": [
      "Harshit Sikchi",
      "Andrea Tirinzoni",
      "Ahmed Touati",
      "Yingchen Xu",
      "Anssi Kanervisto",
      "Scott Niekum",
      "Amy Zhang",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "published": "2025-04-10T16:14:17+00:00",
    "summary": "Unsupervised zero-shot reinforcement learning (RL) has emerged as a powerful paradigm for pretraining behavioral foundation models (BFMs), enabling agents to solve a wide range of downstream tasks specified via reward functions in a zero-shot fashion, i.e., without additional test-time learning or planning. This is achieved by learning self-supervised task embeddings alongside corresponding near-optimal behaviors and incorporating an inference procedure to directly retrieve the latent task embedding and associated policy for any given reward function. Despite promising results, zero-shot policies are often suboptimal due to errors induced by the unsupervised training process, the embedding, and the inference procedure. In this paper, we focus on devising fast adaptation strategies to improve the zero-shot performance of BFMs in a few steps of online interaction with the environment while avoiding any performance drop during the adaptation process. Notably, we demonstrate that existing BFMs learn a set of skills containing more performant policies than those identified by their inference procedure, making them well-suited for fast adaptation. Motivated by this observation, we propose both actor-critic and actor-only fast adaptation strategies that search in the low-dimensional task-embedding space of the pre-trained BFM to rapidly improve the performance of its zero-shot policies on any downstream task. Notably, our approach mitigates the initial \"unlearning\" phase commonly observed when fine-tuning pre-trained RL models. We evaluate our fast adaptation strategies on top of four state-of-the-art zero-shot RL methods in multiple navigation and locomotion domains. Our results show that they achieve 10-40% improvement over their zero-shot performance in a few tens of episodes, outperforming existing baselines."
  },
  {
    "title": "The Role of Buffer Gas in Shaping the D1 Line Spectrum of Potassium Vapour",
    "url": "http://arxiv.org/abs/2504.07888v1",
    "arxiv_id": "2504.07888v1",
    "authors": [
      "Sharaa A. Alqarni",
      "Danielle Pizzey",
      "Steven A Wrathmall",
      "Ifan G Hughes"
    ],
    "published": "2025-04-10T16:01:57+00:00",
    "summary": "In this study, we investigate the effect of buffer gas and magnetic field on the spectral line shapes of the potassium D1 transition using sealed vapour cells filled with varying amounts of neon as a buffer gas. Employing a dual-temperature control system, we independently manipulate the cell body and stem temperatures to explore Doppler and collisional effects on the spectrum. Our results show how the Voigt spectral profile changes from Gaussian- to Lorentzian-dominated forms due to pressure broadening and shifts caused by collisions between potassium atoms and neon. Our measurements are in excellent agreement with the literature values for potassium-neon collisions. For the first time we were able to incorporate the buffer-gas shift and broadening into the modified Voigt profile via the ElecSus code, and found excellent agreement between the predicted and measured line profiles. We also analyse the potassium D1 spectral lines in the hyperfine Paschen-Back regime using strong magnetic fields, demonstrating how Zeeman splitting modifies the pressure-broadened line shape. This work provides valuable insights into collision-induced broadening and shifts, enhancing our understanding of potassium spectroscopy and its application in the development of advanced magneto-optical filters for solar physics and other applications."
  },
  {
    "title": "Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual Learning",
    "url": "http://arxiv.org/abs/2504.07097v1",
    "arxiv_id": "2504.07097v1",
    "authors": [
      "Nikhil Shivakumar Nayak",
      "Krishnateja Killamsetty",
      "Ligong Han",
      "Abhishek Bhandwaldar",
      "Prateek Chanda",
      "Kai Xu",
      "Hao Wang",
      "Aldo Pareja",
      "Oleg Silkin",
      "Mustafa Eyceoz",
      "Akash Srivastava"
    ],
    "published": "2025-04-09T17:59:42+00:00",
    "summary": "Continual learning in large language models (LLMs) is prone to catastrophic forgetting, where adapting to new tasks significantly degrades performance on previously learned ones. Existing methods typically rely on low-rank, parameter-efficient updates that limit the model's expressivity and introduce additional parameters per task, leading to scalability issues. To address these limitations, we propose a novel continual full fine-tuning approach leveraging adaptive singular value decomposition (SVD). Our method dynamically identifies task-specific low-rank parameter subspaces and constrains updates to be orthogonal to critical directions associated with prior tasks, thus effectively minimizing interference without additional parameter overhead or storing previous task gradients. We evaluate our approach extensively on standard continual learning benchmarks using both encoder-decoder (T5-Large) and decoder-only (LLaMA-2 7B) models, spanning diverse tasks including classification, generation, and reasoning. Empirically, our method achieves state-of-the-art results, up to 7% higher average accuracy than recent baselines like O-LoRA, and notably maintains the model's general linguistic capabilities, instruction-following accuracy, and safety throughout the continual learning process by reducing forgetting to near-negligible levels. Our adaptive SVD framework effectively balances model plasticity and knowledge retention, providing a practical, theoretically grounded, and computationally scalable solution for continual learning scenarios in large language models."
  },
  {
    "title": "Neural Motion Simulator: Pushing the Limit of World Models in Reinforcement Learning",
    "url": "http://arxiv.org/abs/2504.07095v1",
    "arxiv_id": "2504.07095v1",
    "authors": [
      "Chenjie Hao",
      "Weyl Lu",
      "Yifan Xu",
      "Yubei Chen"
    ],
    "published": "2025-04-09T17:59:32+00:00",
    "summary": "An embodied system must not only model the patterns of the external world but also understand its own motion dynamics. A motion dynamic model is essential for efficient skill acquisition and effective planning. In this work, we introduce the neural motion simulator (MoSim), a world model that predicts the future physical state of an embodied system based on current observations and actions. MoSim achieves state-of-the-art performance in physical state prediction and provides competitive performance across a range of downstream tasks. This works shows that when a world model is accurate enough and performs precise long-horizon predictions, it can facilitate efficient skill acquisition in imagined worlds and even enable zero-shot reinforcement learning. Furthermore, MoSim can transform any model-free reinforcement learning (RL) algorithm into a model-based approach, effectively decoupling physical environment modeling from RL algorithm development. This separation allows for independent advancements in RL algorithms and world modeling, significantly improving sample efficiency and enhancing generalization capabilities. Our findings highlight that world models for motion dynamics is a promising direction for developing more versatile and capable embodied systems."
  },
  {
    "title": "FlashDepth: Real-time Streaming Video Depth Estimation at 2K Resolution",
    "url": "http://arxiv.org/abs/2504.07093v1",
    "arxiv_id": "2504.07093v1",
    "authors": [
      "Gene Chou",
      "Wenqi Xian",
      "Guandao Yang",
      "Mohamed Abdelfattah",
      "Bharath Hariharan",
      "Noah Snavely",
      "Ning Yu",
      "Paul Debevec"
    ],
    "published": "2025-04-09T17:59:31+00:00",
    "summary": "A versatile video depth estimation model should (1) be accurate and consistent across frames, (2) produce high-resolution depth maps, and (3) support real-time streaming. We propose FlashDepth, a method that satisfies all three requirements, performing depth estimation on a 2044x1148 streaming video at 24 FPS. We show that, with careful modifications to pretrained single-image depth models, these capabilities are enabled with relatively little data and training. We evaluate our approach across multiple unseen datasets against state-of-the-art depth models, and find that ours outperforms them in terms of boundary sharpness and speed by a significant margin, while maintaining competitive accuracy. We hope our model will enable various applications that require high-resolution depth, such as video editing, and online decision-making, such as robotics."
  },
  {
    "title": "AssistanceZero: Scalably Solving Assistance Games",
    "url": "http://arxiv.org/abs/2504.07091v1",
    "arxiv_id": "2504.07091v1",
    "authors": [
      "Cassidy Laidlaw",
      "Eli Bronstein",
      "Timothy Guo",
      "Dylan Feng",
      "Lukas Berglund",
      "Justin Svegliato",
      "Stuart Russell",
      "Anca Dragan"
    ],
    "published": "2025-04-09T17:59:03+00:00",
    "summary": "Assistance games are a promising alternative to reinforcement learning from human feedback (RLHF) for training AI assistants. Assistance games resolve key drawbacks of RLHF, such as incentives for deceptive behavior, by explicitly modeling the interaction between assistant and user as a two-player game where the assistant cannot observe their shared goal. Despite their potential, assistance games have only been explored in simple settings. Scaling them to more complex environments is difficult because it requires both solving intractable decision-making problems under uncertainty and accurately modeling human users' behavior. We present the first scalable approach to solving assistance games and apply it to a new, challenging Minecraft-based assistance game with over $10^{400}$ possible goals. Our approach, AssistanceZero, extends AlphaZero with a neural network that predicts human actions and rewards, enabling it to plan under uncertainty. We show that AssistanceZero outperforms model-free RL algorithms and imitation learning in the Minecraft-based assistance game. In a human study, our AssistanceZero-trained assistant significantly reduces the number of actions participants take to complete building tasks in Minecraft. Our results suggest that assistance games are a tractable framework for training effective AI assistants in complex environments. Our code and models are available at https://github.com/cassidylaidlaw/minecraft-building-assistance-game."
  },
  {
    "title": "A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths to Reproducibility",
    "url": "http://arxiv.org/abs/2504.07086v1",
    "arxiv_id": "2504.07086v1",
    "authors": [
      "Andreas Hochlehnert",
      "Hardik Bhatnagar",
      "Vishaal Udandarao",
      "Samuel Albanie",
      "Ameya Prabhu",
      "Matthias Bethge"
    ],
    "published": "2025-04-09T17:58:17+00:00",
    "summary": "Reasoning has emerged as the next major frontier for language models (LMs), with rapid advances from both academic and industrial labs. However, this progress often outpaces methodological rigor, with many evaluations relying on benchmarking practices that lack transparency, robustness, or statistical grounding. In this work, we conduct a comprehensive empirical study and find that current mathematical reasoning benchmarks are highly sensitive to subtle implementation choices - including decoding parameters, random seeds, prompt formatting, and even hardware and software-framework configurations. Performance gains reported in recent studies frequently hinge on unclear comparisons or unreported sources of variance. To address these issues, we propose a standardized evaluation framework with clearly defined best practices and reporting standards. Using this framework, we reassess recent methods and find that reinforcement learning (RL) approaches yield only modest improvements - far below prior claims - and are prone to overfitting, especially on small-scale benchmarks like AIME24. In contrast, supervised finetuning (SFT) methods show consistently stronger generalization. To foster reproducibility, we release all code, prompts, and model outputs, for reasoning benchmarks, establishing more rigorous foundations for future work."
  },
  {
    "title": "Underwater Robotic Simulators Review for Autonomous System Development",
    "url": "http://arxiv.org/abs/2504.06245v1",
    "arxiv_id": "2504.06245v1",
    "authors": [
      "Sara Aldhaheri",
      "Yang Hu",
      "Yongchang Xie",
      "Peng Wu",
      "Dimitrios Kanoulas",
      "Yuanchang Liu"
    ],
    "published": "2025-04-08T17:43:48+00:00",
    "summary": "The increasing complexity of underwater robotic systems has led to a surge in simulation platforms designed to support perception, planning, and control tasks in marine environments. However, selecting the most appropriate underwater robotic simulator (URS) remains a challenge due to wide variations in fidelity, extensibility, and task suitability. This paper presents a comprehensive review and comparative analysis of five state-of-the-art, ROS-compatible, open-source URSs: Stonefish, DAVE, HoloOcean, MARUS, and UNav-Sim. Each simulator is evaluated across multiple criteria including sensor fidelity, environmental realism, sim-to-real capabilities, and research impact. We evaluate them across architectural design, sensor and physics modeling, task capabilities, and research impact. Additionally, we discuss ongoing challenges in sim-to-real transfer and highlight the need for standardization and benchmarking in the field. Our findings aim to guide practitioners in selecting effective simulation environments and inform future development of more robust and transferable URSs."
  },
  {
    "title": "Addressing Relative Degree Issues in Control Barrier Function Synthesis with Physics-Informed Neural Networks",
    "url": "http://arxiv.org/abs/2504.06242v1",
    "arxiv_id": "2504.06242v1",
    "authors": [
      "Lukas Brunke",
      "Siqi Zhou",
      "Francesco D'Orazio",
      "Angela P. Schoellig"
    ],
    "published": "2025-04-08T17:41:43+00:00",
    "summary": "In robotics, control barrier function (CBF)-based safety filters are commonly used to enforce state constraints. A critical challenge arises when the relative degree of the CBF varies across the state space. This variability can create regions within the safe set where the control input becomes unconstrained. When implemented as a safety filter, this may result in chattering near the safety boundary and ultimately compromise system safety. To address this issue, we propose a novel approach for CBF synthesis by formulating it as solving a set of boundary value problems. The solutions to the boundary value problems are determined using physics-informed neural networks (PINNs). Our approach ensures that the synthesized CBFs maintain a constant relative degree across the set of admissible states, thereby preventing unconstrained control scenarios. We illustrate the approach in simulation and further verify it through real-world quadrotor experiments, demonstrating its effectiveness in preserving desired system safety properties."
  },
  {
    "title": "Dictionary-free Koopman Predictive Control for Autonomous Vehicles in Mixed Traffic",
    "url": "http://arxiv.org/abs/2504.06240v1",
    "arxiv_id": "2504.06240v1",
    "authors": [
      "Xu Shang",
      "Zhaojian Li",
      "Yang Zheng"
    ],
    "published": "2025-04-08T17:40:54+00:00",
    "summary": "Koopman Model Predictive Control (KMPC) and Data-EnablEd Predictive Control (DeePC) use linear models to approximate nonlinear systems and integrate them with predictive control. Both approaches have recently demonstrated promising performance in controlling Connected and Autonomous Vehicles (CAVs) in mixed traffic. However, selecting appropriate lifting functions for the Koopman operator in KMPC is challenging, while the data-driven representation from Willems' fundamental lemma in DeePC must be updated to approximate the local linearization when the equilibrium traffic state changes. In this paper, we propose a dictionary-free Koopman model predictive control (DF-KMPC) for CAV control. In particular, we first introduce a behavioral perspective to identify the optimal dictionary-free Koopman linear model. We then utilize an iterative algorithm to compute a data-driven approximation of the dictionary-free Koopman representation. Integrating this data-driven linear representation with predictive control leads to our DF-KMPC, which eliminates the need to select lifting functions and update the traffic equilibrium state. Nonlinear traffic simulations show that DF-KMPC effectively mitigates traffic waves and improves tracking performance."
  },
  {
    "title": "Accessible and Pedagogically-Grounded Explainability for Human-Robot Interaction: A Framework Based on UDL and Symbolic Interfaces",
    "url": "http://arxiv.org/abs/2504.06189v1",
    "arxiv_id": "2504.06189v1",
    "authors": [
      "Francisco J. Rodr\u00edguez Lera",
      "Raquel Fern\u00e1ndez Hern\u00e1ndez",
      "Sonia Lopez Gonz\u00e1lez",
      "Miguel Angel Gonz\u00e1lez-Santamarta",
      "Francisco Jes\u00fas Rodr\u00edguez Sedano",
      "Camino Fernandez Llamas"
    ],
    "published": "2025-04-08T16:33:52+00:00",
    "summary": "This paper presents a novel framework for accessible and pedagogically-grounded robot explainability, designed to support human-robot interaction (HRI) with users who have diverse cognitive, communicative, or learning needs. We combine principles from Universal Design for Learning (UDL) and Universal Design (UD) with symbolic communication strategies to facilitate the alignment of mental models between humans and robots. Our approach employs Asterics Grid and ARASAAC pictograms as a multimodal, interpretable front-end, integrated with a lightweight HTTP-to-ROS 2 bridge that enables real-time interaction and explanation triggering. We emphasize that explainability is not a one-way function but a bidirectional process, where human understanding and robot transparency must co-evolve. We further argue that in educational or assistive contexts, the role of a human mediator (e.g., a teacher) may be essential to support shared understanding. We validate our framework with examples of multimodal explanation boards and discuss how it can be extended to different scenarios in education, assistive robotics, and inclusive AI."
  },
  {
    "title": "Plug and Play Distributed Control of Clustered Energy Hub Networks",
    "url": "http://arxiv.org/abs/2504.06179v1",
    "arxiv_id": "2504.06179v1",
    "authors": [
      "Varsha Behrunani",
      "Cara Koepele",
      "Jared Miller",
      "Ahmed Aboudonia",
      "Philipp Heer",
      "Roy S. Smith",
      "John Lygeros"
    ],
    "published": "2025-04-08T16:21:23+00:00",
    "summary": "The transition to renewable energy is driving the rise of distributed multi-energy systems, in which individual energy hubs and prosumers (e.g., homes, industrial campuses) generate, store, and trade energy. Economic Model Predictive Control (MPC) schemes are widely used to optimize operation of energy hubs by efficiently dispatching resources and minimizing costs while ensuring operational constraints are met. Peer-to-peer (P2P) energy trading among hubs enhances network efficiency and reduces costs but also increases computational and privacy challenges, especially as the network scales. Additionally, current distributed control techniques require global recomputation whenever the network topology changes, limiting scalability. To address these challenges, we propose a clustering-based P2P trading framework that enables plug-and-play operation, allowing energy hubs to seamlessly join or leave without requiring network-wide controller updates. The impact is restricted to the hubs within the affected cluster. The energy trading problem is formulated as a bi-level bargaining game, where inter-cluster trading commitments are determined at the cluster level, while energy dispatch and cost-sharing among hubs within a cluster are refined at the hub level. Both levels are solved in a distributed manner using ADMM, ensuring computational feasibility and privacy preservation. Moreover, we develop plug-and-play procedures to handle dynamic topology changes at both the hub and cluster levels, minimizing disruptions across the network. Simulation results demonstrate that the proposed bi-level framework reduces operational costs, and enables scalable energy management under plug-and-play operation."
  },
  {
    "title": "Ionomeric extracellular matrices for dynamic soft robotic tissue engineering devices through protein sulfonation",
    "url": "http://arxiv.org/abs/2504.05302v1",
    "arxiv_id": "2504.05302v1",
    "authors": [
      "Matthew K Burgess",
      "Ryan T Murray",
      "Veronica M Lucian",
      "Zekun Liu",
      "Robin O Cleveland",
      "Callum J Beeston",
      "Malavika Nair"
    ],
    "published": "2025-04-07T17:59:11+00:00",
    "summary": "Conventional tissue engineering methodologies frequently depend on pharmacological strategies to induce or expedite tissue repair. However, bioengineered strategies incorporating biophysical stimulation have emerged as promising alternatives. Electroactive materials facilitate the provision of controlled electrical, mechanical, and electromechanical stimuli, which support cell proliferation and tissue remodelling. Despite their ability to supply external electrical and mechanical stimuli to the tissue microenvironment, the electroactive polymers in use today often lack critical biochemical signals essential for native-like cell-cell and cell-scaffold interactions, thereby constraining their regenerative capabilities. To address the demand for biomimetic materials that possess enhanced capabilities in promoting cell and tissue stimulation, we present the development of a novel class of polymers called ionomeric extracellular matrices (iECMs). By utilising the linker-mediated conjugation of sulfonic acid biomolecules (taurine) to the backbone of an extracellular matrix protein (collagen), we illustrate the potential of iECMs as the first electromechanical actuating material platform derived entirely from ECM materials, paving the way for dynamic and soft-robotic platforms for a wide range of tissue engineering applications."
  },
  {
    "title": "Truthful or Fabricated? Using Causal Attribution to Mitigate Reward Hacking in Explanations",
    "url": "http://arxiv.org/abs/2504.05294v1",
    "arxiv_id": "2504.05294v1",
    "authors": [
      "Pedro Ferreira",
      "Wilker Aziz",
      "Ivan Titov"
    ],
    "published": "2025-04-07T17:49:23+00:00",
    "summary": "Chain-of-thought explanations are widely used to inspect the decision process of large language models (LLMs) and to evaluate the trustworthiness of model outputs, making them important for effective collaboration between LLMs and humans. We demonstrate that preference optimization - a key step in the alignment phase - can inadvertently reduce the faithfulness of these explanations. This occurs because the reward model (RM), which guides alignment, is tasked with optimizing both the expected quality of the response and the appropriateness of the explanations (e.g., minimizing bias or adhering to safety standards), creating potential conflicts. The RM lacks a mechanism to assess the consistency between the model's internal decision process and the generated explanation. Consequently, the LLM may engage in \"reward hacking\" by producing a final response that scores highly while giving an explanation tailored to maximize reward rather than accurately reflecting its reasoning. To address this issue, we propose enriching the RM's input with a causal attribution of the prediction, allowing the RM to detect discrepancies between the generated self-explanation and the model's decision process. In controlled settings, we show that this approach reduces the tendency of the LLM to generate misleading explanations."
  },
  {
    "title": "Using Physiological Measures, Gaze, and Facial Expressions to Model Human Trust in a Robot Partner",
    "url": "http://arxiv.org/abs/2504.05291v1",
    "arxiv_id": "2504.05291v1",
    "authors": [
      "Haley N. Green",
      "Tariq Iqbal"
    ],
    "published": "2025-04-07T17:45:17+00:00",
    "summary": "With robots becoming increasingly prevalent in various domains, it has become crucial to equip them with tools to achieve greater fluency in interactions with humans. One of the promising areas for further exploration lies in human trust. A real-time, objective model of human trust could be used to maximize productivity, preserve safety, and mitigate failure. In this work, we attempt to use physiological measures, gaze, and facial expressions to model human trust in a robot partner. We are the first to design an in-person, human-robot supervisory interaction study to create a dedicated trust dataset. Using this dataset, we train machine learning algorithms to identify the objective measures that are most indicative of trust in a robot partner, advancing trust prediction in human-robot interactions. Our findings indicate that a combination of sensor modalities (blood volume pulse, electrodermal activity, skin temperature, and gaze) can enhance the accuracy of detecting human trust in a robot partner. Furthermore, the Extra Trees, Random Forest, and Decision Trees classifiers exhibit consistently better performance in measuring the person's trust in the robot partner. These results lay the groundwork for constructing a real-time trust model for human-robot interaction, which could foster more efficient interactions between humans and robots."
  },
  {
    "title": "RobustDexGrasp: Robust Dexterous Grasping of General Objects from Single-view Perception",
    "url": "http://arxiv.org/abs/2504.05287v1",
    "arxiv_id": "2504.05287v1",
    "authors": [
      "Hui Zhang",
      "Zijian Wu",
      "Linyi Huang",
      "Sammy Christen",
      "Jie Song"
    ],
    "published": "2025-04-07T17:38:19+00:00",
    "summary": "Robust grasping of various objects from single-view perception is fundamental for dexterous robots. Previous works often rely on fully observable objects, expert demonstrations, or static grasping poses, which restrict their generalization ability and adaptability to external disturbances. In this paper, we present a reinforcement-learning-based framework that enables zero-shot dynamic dexterous grasping of a wide range of unseen objects from single-view perception, while performing adaptive motions to external disturbances. We utilize a hand-centric object representation for shape feature extraction that emphasizes interaction-relevant local shapes, enhancing robustness to shape variance and uncertainty. To enable effective hand adaptation to disturbances with limited observations, we propose a mixed curriculum learning strategy, which first utilizes imitation learning to distill a policy trained with privileged real-time visual-tactile feedback, and gradually transfers to reinforcement learning to learn adaptive motions under disturbances caused by observation noises and dynamic randomization. Our experiments demonstrate strong generalization in grasping unseen objects with random poses, achieving success rates of 97.0% across 247,786 simulated objects and 94.6% across 512 real objects. We also demonstrate the robustness of our method to various disturbances, including unobserved object movement and external forces, through both quantitative and qualitative evaluations. Project Page: https://zdchan.github.io/Robust_DexGrasp/"
  },
  {
    "title": "Manipulating phases in many-body interacting systems with subsystem resetting",
    "url": "http://arxiv.org/abs/2504.05260v1",
    "arxiv_id": "2504.05260v1",
    "authors": [
      "Anish Acharya",
      "Rupak Majumder",
      "Shamik Gupta"
    ],
    "published": "2025-04-07T16:53:44+00:00",
    "summary": "Stabilizing thermodynamically unstable phases in many-body systems -- such as suppressing pathological neuronal synchronization in Parkinson's disease or maintaining magnetic order across broad temperature ranges -- remains a persistent challenge. In traditional approaches, such phases are stabilized through intervening in the dynamics of all system constituents or introducing additional interactions. Here, we offer a hitherto-unexplored alternative -- subsystem resetting, whereby intervention in the dynamics of only a part of the system, and that too only occasionally in time, is implemented through resetting its state to a reset configuration. Just playing with a few parameters, e.g., the nature of the reset configuration and the size of the reset subsystem, one achieves a remarkable and robust control over the phase diagram of the bare dynamics. We demonstrate that these universal effects span a wide variety of scenarios, including equilibrium and non-equilibrium, mean-field and non-mean-field dynamics, with and without quenched disorder. Despite the challenges posed by memory effects, we obtain explicit analytical predictions, validated by simulations."
  },
  {
    "title": "SeGuE: Semantic Guided Exploration for Mobile Robots",
    "url": "http://arxiv.org/abs/2504.03629v1",
    "arxiv_id": "2504.03629v1",
    "authors": [
      "Cody Simons",
      "Aritra Samanta",
      "Amit K. Roy-Chowdhury",
      "Konstantinos Karydis"
    ],
    "published": "2025-04-04T17:46:45+00:00",
    "summary": "The rise of embodied AI applications has enabled robots to perform complex tasks which require a sophisticated understanding of their environment. To enable successful robot operation in such settings, maps must be constructed so that they include semantic information, in addition to geometric information. In this paper, we address the novel problem of semantic exploration, whereby a mobile robot must autonomously explore an environment to fully map both its structure and the semantic appearance of features. We develop a method based on next-best-view exploration, where potential poses are scored based on the semantic features visible from that pose. We explore two alternative methods for sampling potential views and demonstrate the effectiveness of our framework in both simulation and physical experiments. Automatic creation of high-quality semantic maps can enable robots to better understand and interact with their environments and enable future embodied AI applications to be more easily deployed."
  },
  {
    "title": "Align to Structure: Aligning Large Language Models with Structural Information",
    "url": "http://arxiv.org/abs/2504.03622v1",
    "arxiv_id": "2504.03622v1",
    "authors": [
      "Zae Myung Kim",
      "Anand Ramachandran",
      "Farideh Tavazoee",
      "Joo-Kyung Kim",
      "Oleg Rokhlenko",
      "Dongyeop Kang"
    ],
    "published": "2025-04-04T17:40:04+00:00",
    "summary": "Generating long, coherent text remains a challenge for large language models (LLMs), as they lack hierarchical planning and structured organization in discourse generation. We introduce Structural Alignment, a novel method that aligns LLMs with human-like discourse structures to enhance long-form text generation. By integrating linguistically grounded discourse frameworks into reinforcement learning, our approach guides models to produce coherent and well-organized outputs. We employ a dense reward scheme within a Proximal Policy Optimization framework, assigning fine-grained, token-level rewards based on the discourse distinctiveness relative to human writing. Two complementary reward models are evaluated: the first improves readability by scoring surface-level textual features to provide explicit structuring, while the second reinforces deeper coherence and rhetorical sophistication by analyzing global discourse patterns through hierarchical discourse motifs, outperforming both standard and RLHF-enhanced models in tasks such as essay generation and long-document summarization. All training data and code will be publicly shared at https://github.com/minnesotanlp/struct_align."
  },
  {
    "title": "Optimization of a Triangular Delaunay Mesh Generator using Reinforcement Learning",
    "url": "http://arxiv.org/abs/2504.03610v1",
    "arxiv_id": "2504.03610v1",
    "authors": [
      "Will Thacher",
      "Per-Olof Persson",
      "Yulong Pan"
    ],
    "published": "2025-04-04T17:30:50+00:00",
    "summary": "In this work we introduce a triangular Delaunay mesh generator that can be trained using reinforcement learning to maximize a given mesh quality metric. Our mesh generator consists of a graph neural network that distributes and modifies vertices, and a standard Delaunay algorithm to triangulate the vertices. We explore various design choices and evaluate our mesh generator on various tasks including mesh generation, mesh improvement, and producing variable resolution meshes. The learned mesh generator outputs meshes that are comparable to those produced by Triangle and DistMesh, two popular Delaunay-based mesh generators."
  },
  {
    "title": "Robust Human Registration with Body Part Segmentation on Noisy Point Clouds",
    "url": "http://arxiv.org/abs/2504.03602v1",
    "arxiv_id": "2504.03602v1",
    "authors": [
      "Kai Lascheit",
      "Daniel Barath",
      "Marc Pollefeys",
      "Leonidas Guibas",
      "Francis Engelmann"
    ],
    "published": "2025-04-04T17:17:33+00:00",
    "summary": "Registering human meshes to 3D point clouds is essential for applications such as augmented reality and human-robot interaction but often yields imprecise results due to noise and background clutter in real-world data. We introduce a hybrid approach that incorporates body-part segmentation into the mesh fitting process, enhancing both human pose estimation and segmentation accuracy. Our method first assigns body part labels to individual points, which then guide a two-step SMPL-X fitting: initial pose and orientation estimation using body part centroids, followed by global refinement of the point cloud alignment. Additionally, we demonstrate that the fitted human mesh can refine body part labels, leading to improved segmentation. Evaluations on the cluttered and noisy real-world datasets InterCap, EgoBody, and BEHAVE show that our approach significantly outperforms prior methods in both pose estimation and segmentation accuracy. Code and results are available on our project website: https://segfit.github.io"
  },
  {
    "title": "Real-is-Sim: Bridging the Sim-to-Real Gap with a Dynamic Digital Twin for Real-World Robot Policy Evaluation",
    "url": "http://arxiv.org/abs/2504.03597v1",
    "arxiv_id": "2504.03597v1",
    "authors": [
      "Jad Abou-Chakra",
      "Lingfeng Sun",
      "Krishan Rana",
      "Brandon May",
      "Karl Schmeckpeper",
      "Maria Vittoria Minniti",
      "Laura Herlant"
    ],
    "published": "2025-04-04T17:05:56+00:00",
    "summary": "Recent advancements in behavior cloning have enabled robots to perform complex manipulation tasks. However, accurately assessing training performance remains challenging, particularly for real-world applications, as behavior cloning losses often correlate poorly with actual task success. Consequently, researchers resort to success rate metrics derived from costly and time-consuming real-world evaluations, making the identification of optimal policies and detection of overfitting or underfitting impractical. To address these issues, we propose real-is-sim, a novel behavior cloning framework that incorporates a dynamic digital twin (based on Embodied Gaussians) throughout the entire policy development pipeline: data collection, training, and deployment. By continuously aligning the simulated world with the physical world, demonstrations can be collected in the real world with states extracted from the simulator. The simulator enables flexible state representations by rendering image inputs from any viewpoint or extracting low-level state information from objects embodied within the scene. During training, policies can be directly evaluated within the simulator in an offline and highly parallelizable manner. Finally, during deployment, policies are run within the simulator where the real robot directly tracks the simulated robot's joints, effectively decoupling policy execution from real hardware and mitigating traditional domain-transfer challenges. We validate real-is-sim on the PushT manipulation task, demonstrating strong correlation between success rates obtained in the simulator and real-world evaluations. Videos of our system can be found at https://realissim.rai-inst.com."
  },
  {
    "title": "Concept Lancet: Image Editing with Compositional Representation Transplant",
    "url": "http://arxiv.org/abs/2504.02828v1",
    "arxiv_id": "2504.02828v1",
    "authors": [
      "Jinqi Luo",
      "Tianjiao Ding",
      "Kwan Ho Ryan Chan",
      "Hancheng Min",
      "Chris Callison-Burch",
      "Ren\u00e9 Vidal"
    ],
    "published": "2025-04-03T17:59:58+00:00",
    "summary": "Diffusion models are widely used for image editing tasks. Existing editing methods often design a representation manipulation procedure by curating an edit direction in the text embedding or score space. However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task. Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error. To address this challenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing. At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts. This allows us to accurately estimate the presence of concepts in each image, which informs the edit. Based on the editing task (replace/add/remove), we perform a customized concept transplant process to impose the corresponding editing direction. To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary. Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation."
  },
  {
    "title": "Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence",
    "url": "http://arxiv.org/abs/2504.02799v1",
    "arxiv_id": "2504.02799v1",
    "authors": [
      "Anita Rau",
      "Mark Endo",
      "Josiah Aklilu",
      "Jaewoo Heo",
      "Khaled Saab",
      "Alberto Paderno",
      "Jeffrey Jopling",
      "F. Christopher Holsinger",
      "Serena Yeung-Levy"
    ],
    "published": "2025-04-03T17:42:56+00:00",
    "summary": "Large Vision-Language Models offer a new paradigm for AI-driven image understanding, enabling models to perform tasks without task-specific training. This flexibility holds particular promise across medicine, where expert-annotated data is scarce. Yet, VLMs' practical utility in intervention-focused domains--especially surgery, where decision-making is subjective and clinical scenarios are variable--remains uncertain. Here, we present a comprehensive analysis of 11 state-of-the-art VLMs across 17 key visual understanding tasks in surgical AI--from anatomy recognition to skill assessment--using 13 datasets spanning laparoscopic, robotic, and open procedures. In our experiments, VLMs demonstrate promising generalizability, at times outperforming supervised models when deployed outside their training setting. In-context learning, incorporating examples during testing, boosted performance up to three-fold, suggesting adaptability as a key strength. Still, tasks requiring spatial or temporal reasoning remained difficult. Beyond surgery, our findings offer insights into VLMs' potential for tackling complex and dynamic scenarios in clinical and broader real-world applications."
  },
  {
    "title": "Spline-based Transformers",
    "url": "http://arxiv.org/abs/2504.02797v1",
    "arxiv_id": "2504.02797v1",
    "authors": [
      "Prashanth Chandran",
      "Agon Serifi",
      "Markus Gross",
      "Moritz B\u00e4cher"
    ],
    "published": "2025-04-03T17:42:07+00:00",
    "summary": "We introduce Spline-based Transformers, a novel class of Transformer models that eliminate the need for positional encoding. Inspired by workflows using splines in computer animation, our Spline-based Transformers embed an input sequence of elements as a smooth trajectory in latent space. Overcoming drawbacks of positional encoding such as sequence length extrapolation, Spline-based Transformers also provide a novel way for users to interact with transformer latent spaces by directly manipulating the latent control points to create new latent trajectories and sequences. We demonstrate the superior performance of our approach in comparison to conventional positional encoding on a variety of datasets, ranging from synthetic 2D to large-scale real-world datasets of images, 3D shapes, and animations."
  },
  {
    "title": "Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets",
    "url": "http://arxiv.org/abs/2504.02792v1",
    "arxiv_id": "2504.02792v1",
    "authors": [
      "Chuning Zhu",
      "Raymond Yu",
      "Siyuan Feng",
      "Benjamin Burchfiel",
      "Paarth Shah",
      "Abhishek Gupta"
    ],
    "published": "2025-04-03T17:38:59+00:00",
    "summary": "Imitation learning has emerged as a promising approach towards building generalist robots. However, scaling imitation learning for large robot foundation models remains challenging due to its reliance on high-quality expert demonstrations. Meanwhile, large amounts of video data depicting a wide range of environments and diverse behaviors are readily available. This data provides a rich source of information about real-world dynamics and agent-environment interactions. Leveraging this data directly for imitation learning, however, has proven difficult due to the lack of action annotation required for most contemporary methods. In this work, we present Unified World Models (UWM), a framework that allows for leveraging both video and action data for policy learning. Specifically, a UWM integrates an action diffusion process and a video diffusion process within a unified transformer architecture, where independent diffusion timesteps govern each modality. We show that by simply controlling each diffusion timestep, UWM can flexibly represent a policy, a forward dynamics, an inverse dynamics, and a video generator. Through simulated and real-world experiments, we show that: (1) UWM enables effective pretraining on large-scale multitask robot datasets with both dynamics and action predictions, resulting in more generalizable and robust policies than imitation learning, (2) UWM naturally facilitates learning from action-free video data through independent control of modality-specific diffusion timesteps, further improving the performance of finetuned policies. Our results suggest that UWM offers a promising step toward harnessing large, heterogeneous datasets for scalable robot learning, and provides a simple unification between the often disparate paradigms of imitation learning and world modeling. Videos and code are available at https://weirdlabuw.github.io/uwm/."
  },
  {
    "title": "GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation",
    "url": "http://arxiv.org/abs/2504.02782v1",
    "arxiv_id": "2504.02782v1",
    "authors": [
      "Zhiyuan Yan",
      "Junyan Ye",
      "Weijia Li",
      "Zilong Huang",
      "Shenghai Yuan",
      "Xiangyang He",
      "Kaiqing Lin",
      "Jun He",
      "Conghui He",
      "Li Yuan"
    ],
    "published": "2025-04-03T17:23:16+00:00",
    "summary": "The recent breakthroughs in OpenAI's GPT4o model have demonstrated surprisingly good capabilities in image generation and editing, resulting in significant excitement in the community. This technical report presents the first-look evaluation benchmark (named GPT-ImgEval), quantitatively and qualitatively diagnosing GPT-4o's performance across three critical dimensions: (1) generation quality, (2) editing proficiency, and (3) world knowledge-informed semantic synthesis. Across all three tasks, GPT-4o demonstrates strong performance, significantly surpassing existing methods in both image generation control and output quality, while also showcasing exceptional knowledge reasoning capabilities. Furthermore, based on the GPT-4o's generated data, we propose a classification-model-based approach to investigate the underlying architecture of GPT-4o, where our empirical results suggest the model consists of an auto-regressive (AR) combined with a diffusion-based head for image decoding, rather than the VAR-like architectures. We also provide a complete speculation on GPT-4o's overall architecture. In addition, we conduct a series of analyses to identify and visualize GPT-4o's specific limitations and the synthetic artifacts commonly observed in its image generation. We also present a comparative study of multi-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the safety implications of GPT-4o's outputs, particularly their detectability by existing image forensic models. We hope that our work can offer valuable insight and provide a reliable benchmark to guide future research, foster reproducibility, and accelerate innovation in the field of image generation and beyond. The codes and datasets used for evaluating GPT-4o can be found at https://github.com/PicoTrex/GPT-ImgEval."
  },
  {
    "title": "Slot-Level Robotic Placement via Visual Imitation from Single Human Video",
    "url": "http://arxiv.org/abs/2504.01959v1",
    "arxiv_id": "2504.01959v1",
    "authors": [
      "Dandan Shan",
      "Kaichun Mo",
      "Wei Yang",
      "Yu-Wei Chao",
      "David Fouhey",
      "Dieter Fox",
      "Arsalan Mousavian"
    ],
    "published": "2025-04-02T17:59:45+00:00",
    "summary": "The majority of modern robot learning methods focus on learning a set of pre-defined tasks with limited or no generalization to new tasks. Extending the robot skillset to novel tasks involves gathering an extensive amount of training data for additional tasks. In this paper, we address the problem of teaching new tasks to robots using human demonstration videos for repetitive tasks (e.g., packing). This task requires understanding the human video to identify which object is being manipulated (the pick object) and where it is being placed (the placement slot). In addition, it needs to re-identify the pick object and the placement slots during inference along with the relative poses to enable robot execution of the task. To tackle this, we propose SLeRP, a modular system that leverages several advanced visual foundation models and a novel slot-level placement detector Slot-Net, eliminating the need for expensive video demonstrations for training. We evaluate our system using a new benchmark of real-world videos. The evaluation results show that SLeRP outperforms several baselines and can be deployed on a real robot."
  },
  {
    "title": "OpenCodeReasoning: Advancing Data Distillation for Competitive Coding",
    "url": "http://arxiv.org/abs/2504.01943v1",
    "arxiv_id": "2504.01943v1",
    "authors": [
      "Wasi Uddin Ahmad",
      "Sean Narenthiran",
      "Somshubra Majumdar",
      "Aleksander Ficek",
      "Siddhartha Jain",
      "Jocelyn Huang",
      "Vahid Noroozi",
      "Boris Ginsburg"
    ],
    "published": "2025-04-02T17:50:31+00:00",
    "summary": "Since the advent of reasoning-based large language models, many have found great success from distilling reasoning capabilities into student models. Such techniques have significantly bridged the gap between reasoning and standard LLMs on coding tasks. Despite this, much of the progress on distilling reasoning models remains locked behind proprietary datasets or lacks details on data curation, filtering and subsequent training. To address this, we construct a superior supervised fine-tuning (SFT) dataset that we use to achieve state-of-the-art coding capability results in models of various sizes. Our distilled models use only SFT to achieve 61.8% on LiveCodeBench and 24.6% on CodeContests, surpassing alternatives trained with reinforcement learning. We then perform analysis on the data sources used to construct our dataset, the impact of code execution filtering, and the importance of instruction/solution diversity. We observe that execution filtering negatively affected benchmark accuracy, leading us to prioritize instruction diversity over solution correctness. Finally, we also analyze the token efficiency and reasoning patterns utilized by these models. We will open-source these datasets and distilled models to the community."
  },
  {
    "title": "End-to-End Driving with Online Trajectory Evaluation via BEV World Model",
    "url": "http://arxiv.org/abs/2504.01941v1",
    "arxiv_id": "2504.01941v1",
    "authors": [
      "Yingyan Li",
      "Yuqi Wang",
      "Yang Liu",
      "Jiawei He",
      "Lue Fan",
      "Zhaoxiang Zhang"
    ],
    "published": "2025-04-02T17:47:23+00:00",
    "summary": "End-to-end autonomous driving has achieved remarkable progress by integrating perception, prediction, and planning into a fully differentiable framework. Yet, to fully realize its potential, an effective online trajectory evaluation is indispensable to ensure safety. By forecasting the future outcomes of a given trajectory, trajectory evaluation becomes much more effective. This goal can be achieved by employing a world model to capture environmental dynamics and predict future states. Therefore, we propose an end-to-end driving framework WoTE, which leverages a BEV World model to predict future BEV states for Trajectory Evaluation. The proposed BEV world model is latency-efficient compared to image-level world models and can be seamlessly supervised using off-the-shelf BEV-space traffic simulators. We validate our framework on both the NAVSIM benchmark and the closed-loop Bench2Drive benchmark based on the CARLA simulator, achieving state-of-the-art performance. Code is released at https://github.com/liyingyanUCAS/WoTE."
  },
  {
    "title": "Strengthening Multi-Robot Systems for SAR: Co-Designing Robotics and Communication Towards 6G",
    "url": "http://arxiv.org/abs/2504.01940v1",
    "arxiv_id": "2504.01940v1",
    "authors": [
      "Juan Bravo-Arrabal",
      "Ricardo V\u00e1zquez-Mart\u00edn",
      "J. J. Fern\u00e1ndez-Lozano",
      "Alfonso Garc\u00eda-Cerezo"
    ],
    "published": "2025-04-02T17:47:11+00:00",
    "summary": "This paper presents field-tested use cases from Search and Rescue (SAR) missions, highlighting the co-design of mobile robots and communication systems to support Edge-Cloud architectures based on 5G Standalone (SA). The main goal is to contribute to the effective cooperation of multiple robots and first responders. Our field experience includes the development of Hybrid Wireless Sensor Networks (H-WSNs) for risk and victim detection, smartphones integrated into the Robot Operating System (ROS) as Edge devices for mission requests and path planning, real-time Simultaneous Localization and Mapping (SLAM) via Multi-Access Edge Computing (MEC), and implementation of Uncrewed Ground Vehicles (UGVs) for victim evacuation in different navigation modes. These experiments, conducted in collaboration with actual first responders, underscore the need for intelligent network resource management, balancing low-latency and high-bandwidth demands. Network slicing is key to ensuring critical emergency services are performed despite challenging communication conditions. The paper identifies architectural needs, lessons learned, and challenges to be addressed by 6G technologies to enhance emergency response capabilities."
  },
  {
    "title": "Overcoming Deceptiveness in Fitness Optimization with Unsupervised Quality-Diversity",
    "url": "http://arxiv.org/abs/2504.01915v1",
    "arxiv_id": "2504.01915v1",
    "authors": [
      "Lisa Coiffard",
      "Paul Templier",
      "Antoine Cully"
    ],
    "published": "2025-04-02T17:18:21+00:00",
    "summary": "Policy optimization seeks the best solution to a control problem according to an objective or fitness function, serving as a fundamental field of engineering and research with applications in robotics. Traditional optimization methods like reinforcement learning and evolutionary algorithms struggle with deceptive fitness landscapes, where following immediate improvements leads to suboptimal solutions. Quality-diversity (QD) algorithms offer a promising approach by maintaining diverse intermediate solutions as stepping stones for escaping local optima. However, QD algorithms require domain expertise to define hand-crafted features, limiting their applicability where characterizing solution diversity remains unclear. In this paper, we show that unsupervised QD algorithms - specifically the AURORA framework, which learns features from sensory data - efficiently solve deceptive optimization problems without domain expertise. By enhancing AURORA with contrastive learning and periodic extinction events, we propose AURORA-XCon, which outperforms all traditional optimization baselines and matches, in some cases even improving by up to 34%, the best QD baseline with domain-specific hand-crafted features. This work establishes a novel application of unsupervised QD algorithms, shifting their focus from discovering novel solutions toward traditional optimization and expanding their potential to domains where defining feature spaces poses challenges."
  },
  {
    "title": "SU-YOLO: Spiking Neural Network for Efficient Underwater Object Detection",
    "url": "http://arxiv.org/abs/2503.24389v1",
    "arxiv_id": "2503.24389v1",
    "authors": [
      "Chenyang Li",
      "Wenxuan Liu",
      "Guoqiang Gong",
      "Xiaobo Ding",
      "Xian Zhong"
    ],
    "published": "2025-03-31T17:59:52+00:00",
    "summary": "Underwater object detection is critical for oceanic research and industrial safety inspections. However, the complex optical environment and the limited resources of underwater equipment pose significant challenges to achieving high accuracy and low power consumption. To address these issues, we propose Spiking Underwater YOLO (SU-YOLO), a Spiking Neural Network (SNN) model. Leveraging the lightweight and energy-efficient properties of SNNs, SU-YOLO incorporates a novel spike-based underwater image denoising method based solely on integer addition, which enhances the quality of feature maps with minimal computational overhead. In addition, we introduce Separated Batch Normalization (SeBN), a technique that normalizes feature maps independently across multiple time steps and is optimized for integration with residual structures to capture the temporal dynamics of SNNs more effectively. The redesigned spiking residual blocks integrate the Cross Stage Partial Network (CSPNet) with the YOLO architecture to mitigate spike degradation and enhance the model's feature extraction capabilities. Experimental results on URPC2019 underwater dataset demonstrate that SU-YOLO achieves mAP of 78.8% with 6.97M parameters and an energy consumption of 2.98 mJ, surpassing mainstream SNN models in both detection accuracy and computational efficiency. These results underscore the potential of SNNs for engineering applications. The code is available in https://github.com/lwxfight/snn-underwater."
  },
  {
    "title": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving",
    "url": "http://arxiv.org/abs/2503.24381v1",
    "arxiv_id": "2503.24381v1",
    "authors": [
      "Yuping Wang",
      "Xiangyu Huang",
      "Xiaokang Sun",
      "Mingxuan Yan",
      "Shuo Xing",
      "Zhengzhong Tu",
      "Jiachen Li"
    ],
    "published": "2025-03-31T17:59:24+00:00",
    "summary": "We introduce UniOcc, a comprehensive, unified benchmark for occupancy forecasting (i.e., predicting future occupancies based on historical information) and current-frame occupancy prediction from camera images. UniOcc unifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and high-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D occupancy labels with per-voxel flow annotations and support for cooperative autonomous driving. In terms of evaluation, unlike existing studies that rely on suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics that do not depend on ground-truth occupancy, enabling robust assessment of additional aspects of occupancy quality. Through extensive experiments on state-of-the-art models, we demonstrate that large-scale, diverse training data and explicit flow information significantly enhance occupancy prediction and forecasting performance."
  },
  {
    "title": "Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1",
    "url": "http://arxiv.org/abs/2503.24376v1",
    "arxiv_id": "2503.24376v1",
    "authors": [
      "Yi Chen",
      "Yuying Ge",
      "Rui Wang",
      "Yixiao Ge",
      "Lu Qiu",
      "Ying Shan",
      "Xihui Liu"
    ],
    "published": "2025-03-31T17:55:23+00:00",
    "summary": "Recent advancements in Chain of Thought (COT) generation have significantly improved the reasoning capabilities of Large Language Models (LLMs), with reinforcement learning (RL) emerging as an effective post-training approach. Multimodal Large Language Models (MLLMs) inherit this reasoning potential but remain underexplored in tasks requiring both perception and logical reasoning. To address this, we introduce SEED-Bench-R1, a benchmark designed to systematically evaluate post-training methods for MLLMs in video understanding. It includes intricate real-world videos and complex everyday planning tasks in the format of multiple-choice questions, requiring sophisticated perception and reasoning. SEED-Bench-R1 assesses generalization through a three-level hierarchy: in-distribution, cross-environment, and cross-environment-task scenarios, equipped with a large-scale training dataset with easily verifiable ground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL with supervised fine-tuning (SFT), demonstrating RL's data efficiency and superior performance on both in-distribution and out-of-distribution tasks, even outperforming SFT on general video understanding benchmarks like LongVideoBench. Our detailed analysis reveals that RL enhances visual perception but often produces less logically coherent reasoning chains. We identify key limitations such as inconsistent reasoning and overlooked visual cues, and suggest future improvements in base model reasoning, reward modeling, and RL robustness against noisy signals."
  },
  {
    "title": "Effectively Controlling Reasoning Models through Thinking Intervention",
    "url": "http://arxiv.org/abs/2503.24370v1",
    "arxiv_id": "2503.24370v1",
    "authors": [
      "Tong Wu",
      "Chong Xiang",
      "Jiachen T. Wang",
      "Prateek Mittal"
    ],
    "published": "2025-03-31T17:50:13+00:00",
    "summary": "Reasoning-enhanced large language models (LLMs) explicitly generate intermediate reasoning steps prior to generating final answers, helping the model excel in complex problem-solving. In this paper, we demonstrate that this emerging generation framework offers a unique opportunity for more fine-grained control over model behavior. We propose Thinking Intervention, a novel paradigm designed to explicitly guide the internal reasoning processes of LLMs by strategically inserting or revising specific thinking tokens. We conduct comprehensive evaluations across multiple tasks, including instruction following on IFEval, instruction hierarchy on SEP, and safety alignment on XSTest and SORRY-Bench. Our results demonstrate that Thinking Intervention significantly outperforms baseline prompting approaches, achieving up to 6.7% accuracy gains in instruction-following scenarios, 15.4% improvements in reasoning about instruction hierarchies, and a 40.0% increase in refusal rates for unsafe prompts using open-source DeepSeek R1 models. Overall, our work opens a promising new research avenue for controlling reasoning LLMs."
  },
  {
    "title": "Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation",
    "url": "http://arxiv.org/abs/2503.24361v1",
    "arxiv_id": "2503.24361v1",
    "authors": [
      "Abhiram Maddukuri",
      "Zhenyu Jiang",
      "Lawrence Yunliang Chen",
      "Soroush Nasiriany",
      "Yuqi Xie",
      "Yu Fang",
      "Wenqi Huang",
      "Zu Wang",
      "Zhenjia Xu",
      "Nikita Chernyadev",
      "Scott Reed",
      "Ken Goldberg",
      "Ajay Mandlekar",
      "Linxi Fan",
      "Yuke Zhu"
    ],
    "published": "2025-03-31T17:39:38+00:00",
    "summary": "Large real-world robot datasets hold great potential to train generalist robot models, but scaling real-world human data collection is time-consuming and resource-intensive. Simulation has great potential in supplementing large-scale data, especially with recent advances in generative AI and automated data generation tools that enable scalable creation of robot behavior datasets. However, training a policy solely in simulation and transferring it to the real world often demands substantial human effort to bridge the reality gap. A compelling alternative is to co-train the policy on a mixture of simulation and real-world datasets. Preliminary studies have recently shown this strategy to substantially improve the performance of a policy over one trained on a limited amount of real-world data. Nonetheless, the community lacks a systematic understanding of sim-and-real co-training and what it takes to reap the benefits of simulation data for real-robot learning. This work presents a simple yet effective recipe for utilizing simulation data to solve vision-based robotic manipulation tasks. We derive this recipe from comprehensive experiments that validate the co-training strategy on various simulation and real-world datasets. Using two domains--a robot arm and a humanoid--across diverse tasks, we demonstrate that simulation data can enhance real-world task performance by an average of 38%, even with notable differences between the simulation and real-world data. Videos and additional results can be found at https://co-training.github.io/"
  },
  {
    "title": "Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation",
    "url": "http://arxiv.org/abs/2503.24361v2",
    "arxiv_id": "2503.24361v2",
    "authors": [
      "Abhiram Maddukuri",
      "Zhenyu Jiang",
      "Lawrence Yunliang Chen",
      "Soroush Nasiriany",
      "Yuqi Xie",
      "Yu Fang",
      "Wenqi Huang",
      "Zu Wang",
      "Zhenjia Xu",
      "Nikita Chernyadev",
      "Scott Reed",
      "Ken Goldberg",
      "Ajay Mandlekar",
      "Linxi Fan",
      "Yuke Zhu"
    ],
    "published": "2025-03-31T17:39:38+00:00",
    "summary": "Large real-world robot datasets hold great potential to train generalist robot models, but scaling real-world human data collection is time-consuming and resource-intensive. Simulation has great potential in supplementing large-scale data, especially with recent advances in generative AI and automated data generation tools that enable scalable creation of robot behavior datasets. However, training a policy solely in simulation and transferring it to the real world often demands substantial human effort to bridge the reality gap. A compelling alternative is to co-train the policy on a mixture of simulation and real-world datasets. Preliminary studies have recently shown this strategy to substantially improve the performance of a policy over one trained on a limited amount of real-world data. Nonetheless, the community lacks a systematic understanding of sim-and-real co-training and what it takes to reap the benefits of simulation data for real-robot learning. This work presents a simple yet effective recipe for utilizing simulation data to solve vision-based robotic manipulation tasks. We derive this recipe from comprehensive experiments that validate the co-training strategy on various simulation and real-world datasets. Using two domains--a robot arm and a humanoid--across diverse tasks, we demonstrate that simulation data can enhance real-world task performance by an average of 38%, even with notable differences between the simulation and real-world data. Videos and additional results can be found at https://co-training.github.io/"
  },
  {
    "title": "Q-Insight: Understanding Image Quality via Visual Reinforcement Learning",
    "url": "http://arxiv.org/abs/2503.22679v1",
    "arxiv_id": "2503.22679v1",
    "authors": [
      "Weiqi Li",
      "Xuanyu Zhang",
      "Shijie Zhao",
      "Yabin Zhang",
      "Junlin Li",
      "Li Zhang",
      "Jian Zhang"
    ],
    "published": "2025-03-28T17:59:54+00:00",
    "summary": "Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight."
  },
  {
    "title": "Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures",
    "url": "http://arxiv.org/abs/2503.22660v1",
    "arxiv_id": "2503.22660v1",
    "authors": [
      "Samuel I. Akinwande",
      "Chelsea Sidrane",
      "Mykel J. Kochenderfer",
      "Clark Barrett"
    ],
    "published": "2025-03-28T17:45:23+00:00",
    "summary": "As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art."
  },
  {
    "title": "Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report)",
    "url": "http://arxiv.org/abs/2503.22646v1",
    "arxiv_id": "2503.22646v1",
    "authors": [
      "Semaan Douglas Wehbe",
      "Stanley Bak"
    ],
    "published": "2025-03-28T17:32:26+00:00",
    "summary": "Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy."
  },
  {
    "title": "Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels",
    "url": "http://arxiv.org/abs/2503.22634v1",
    "arxiv_id": "2503.22634v1",
    "authors": [
      "Adam Wei",
      "Abhinav Agarwal",
      "Boyuan Chen",
      "Rohan Bosworth",
      "Nicholas Pfaff",
      "Russ Tedrake"
    ],
    "published": "2025-03-28T17:25:57+00:00",
    "summary": "In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \\emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials)."
  },
  {
    "title": "Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments",
    "url": "http://arxiv.org/abs/2503.22595v1",
    "arxiv_id": "2503.22595v1",
    "authors": [
      "S. Aaron McClendon",
      "Vishaal Venkatesh",
      "Juan Morinelli"
    ],
    "published": "2025-03-28T16:42:21+00:00",
    "summary": "In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures."
  },
  {
    "title": "HS-SLAM: Hybrid Representation with Structural Supervision for Improved Dense SLAM",
    "url": "http://arxiv.org/abs/2503.21778v1",
    "arxiv_id": "2503.21778v1",
    "authors": [
      "Ziren Gong",
      "Fabio Tosi",
      "Youmin Zhang",
      "Stefano Mattoccia",
      "Matteo Poggi"
    ],
    "published": "2025-03-27T17:59:54+00:00",
    "summary": "NeRF-based SLAM has recently achieved promising results in tracking and reconstruction. However, existing methods face challenges in providing sufficient scene representation, capturing structural information, and maintaining global consistency in scenes emerging significant movement or being forgotten. To this end, we present HS-SLAM to tackle these problems. To enhance scene representation capacity, we propose a hybrid encoding network that combines the complementary strengths of hash-grid, tri-planes, and one-blob, improving the completeness and smoothness of reconstruction. Additionally, we introduce structural supervision by sampling patches of non-local pixels rather than individual rays to better capture the scene structure. To ensure global consistency, we implement an active global bundle adjustment (BA) to eliminate camera drifts and mitigate accumulative errors. Experimental results demonstrate that HS-SLAM outperforms the baselines in tracking and reconstruction accuracy while maintaining the efficiency required for robotics."
  },
  {
    "title": "Video-R1: Reinforcing Video Reasoning in MLLMs",
    "url": "http://arxiv.org/abs/2503.21776v1",
    "arxiv_id": "2503.21776v1",
    "authors": [
      "Kaituo Feng",
      "Kaixiong Gong",
      "Bohao Li",
      "Zonghao Guo",
      "Yibing Wang",
      "Tianshuo Peng",
      "Benyou Wang",
      "Xiangyu Yue"
    ],
    "published": "2025-03-27T17:59:51+00:00",
    "summary": "Inspired by DeepSeek-R1's success in eliciting reasoning abilities through rule-based reinforcement learning (RL), we introduce Video-R1 as the first attempt to systematically explore the R1 paradigm for eliciting video reasoning within multimodal large language models (MLLMs). However, directly applying RL training with the GRPO algorithm to video reasoning presents two primary challenges: (i) a lack of temporal modeling for video reasoning, and (ii) the scarcity of high-quality video-reasoning data. To address these issues, we first propose the T-GRPO algorithm, which encourages models to utilize temporal information in videos for reasoning. Additionally, instead of relying solely on video data, we incorporate high-quality image-reasoning data into the training process. We have constructed two datasets: Video-R1-COT-165k for SFT cold start and Video-R1-260k for RL training, both comprising image and video data. Experimental results demonstrate that Video-R1 achieves significant improvements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as well as on general video benchmarks including MVBench and TempCompass, etc. Notably, Video-R1-7B attains a 35.8% accuracy on video spatial reasoning benchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All codes, models, data are released."
  },
  {
    "title": "Optical control of orbital magnetism in magic angle twisted bilayer graphene",
    "url": "http://arxiv.org/abs/2503.21750v1",
    "arxiv_id": "2503.21750v1",
    "authors": [
      "Eylon Persky",
      "Minhao He",
      "Jiaqi Cai",
      "Takashi Taniguchi",
      "Kenji Watanabe",
      "Xiaodong Xu",
      "Aharon Kapitulnik"
    ],
    "published": "2025-03-27T17:56:23+00:00",
    "summary": "Flat bands in graphene-based moir\\'e structures host a wide range of emerging strongly correlated and topological phenomena. Optically probing and controlling them can reveal important information such as symmetry and dynamics, but have so far been challenging due to the small energy gap compared to optical wavelengths. Here, we report near infrared optical control of orbital magnetism and associated anomalous Hall effects (AHE) in a magic angle twisted bilayer graphene (MATBG) on monolayer WSe$_2$ device. We show that the properties of the AHE, such as hysteresis and amplitude, can be controlled by light near integer moir\\'e fillings, where spontaneous ferromagnetism exists. By modulating the light helicity, we observe periodic modulation of the transverse resistance in a wide range of fillings, indicating light induced orbital magnetization through a large inverse Faraday effect. At the transition between metallic and AHE regimes, we also reveal large and random switching of the Hall resistivity, which are attributed to optical control of percolating cluster of magnetic domains. Our results open the door to optical manipulation of correlation and topology in MATBG and related structures."
  },
  {
    "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics",
    "url": "http://arxiv.org/abs/2503.21735v1",
    "arxiv_id": "2503.21735v1",
    "authors": [
      "Arsham Gholamzadeh Khoee",
      "Shuai Wang",
      "Yinan Yu",
      "Robert Feldt",
      "Dhasarathy Parthasarathy"
    ],
    "published": "2025-03-27T17:48:32+00:00",
    "summary": "Ensuring the reliability and effectiveness of software release decisions is critical, particularly in safety-critical domains like automotive systems. Precise analysis of release validation data, often presented in tabular form, plays a pivotal role in this process. However, traditional methods that rely on manual analysis of extensive test datasets and validation metrics are prone to delays and high costs. Large Language Models (LLMs) offer a promising alternative but face challenges in analytical reasoning, contextual understanding, handling out-of-scope queries, and processing structured test data consistently; limitations that hinder their direct application in safety-critical scenarios. This paper introduces GateLens, an LLM-based tool for analyzing tabular data in the automotive domain. GateLens translates natural language queries into Relational Algebra (RA) expressions and then generates optimized Python code. It outperforms the baseline system on benchmarking datasets, achieving higher F1 scores and handling complex and ambiguous queries with greater robustness. Ablation studies confirm the critical role of the RA module, with performance dropping sharply when omitted. Industrial evaluations reveal that GateLens reduces analysis time by over 80% while maintaining high accuracy and reliability. As demonstrated by presented results, GateLens achieved high performance without relying on few-shot examples, showcasing strong generalization across various query types from diverse company roles. Insights from deploying GateLens with a partner automotive company offer practical guidance for integrating AI into critical workflows such as release validation. Results show that by automating test result analysis, GateLens enables faster, more informed, and dependable release decisions, and can thus advance software scalability and reliability in automotive systems."
  },
  {
    "title": "ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation",
    "url": "http://arxiv.org/abs/2503.21729v1",
    "arxiv_id": "2503.21729v1",
    "authors": [
      "Zhicheng Lee",
      "Shulin Cao",
      "Jinxin Liu",
      "Jiajie Zhang",
      "Weichuan Liu",
      "Xiaoyin Che",
      "Lei Hou",
      "Juanzi Li"
    ],
    "published": "2025-03-27T17:44:18+00:00",
    "summary": "Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely primarily on parametric knowledge, limiting factual accuracy. While recent works equip reinforcement learning (RL)-based LRMs with retrieval capabilities, they suffer from overthinking and lack robustness in reasoning, reducing their effectiveness in question answering (QA) tasks. To address this, we propose ReaRAG, a factuality-enhanced reasoning model that explores diverse queries without excessive iterations. Our solution includes a novel data construction framework with an upper bound on the reasoning chain length. Specifically, we first leverage an LRM to generate deliberate thinking, then select an action from a predefined action space (Search and Finish). For Search action, a query is executed against the RAG engine, where the result is returned as observation to guide reasoning steps later. This process iterates until a Finish action is chosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach outperforms existing baselines on multi-hop QA. Further analysis highlights its strong reflective ability to recognize errors and refine its reasoning trajectory. Our study enhances LRMs' factuality while effectively integrating robust reasoning for Retrieval-Augmented Generation (RAG)."
  }
]