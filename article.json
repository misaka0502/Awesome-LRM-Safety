[
  {
    "title": "Q-Insight: Understanding Image Quality via Visual Reinforcement Learning",
    "url": "http://arxiv.org/abs/2503.22679v1",
    "arxiv_id": "2503.22679v1",
    "authors": [
      "Weiqi Li",
      "Xuanyu Zhang",
      "Shijie Zhao",
      "Yabin Zhang",
      "Junlin Li",
      "Li Zhang",
      "Jian Zhang"
    ],
    "published": "2025-03-28T17:59:54+00:00",
    "summary": "Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight."
  },
  {
    "title": "Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures",
    "url": "http://arxiv.org/abs/2503.22660v1",
    "arxiv_id": "2503.22660v1",
    "authors": [
      "Samuel I. Akinwande",
      "Chelsea Sidrane",
      "Mykel J. Kochenderfer",
      "Clark Barrett"
    ],
    "published": "2025-03-28T17:45:23+00:00",
    "summary": "As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art."
  },
  {
    "title": "Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report)",
    "url": "http://arxiv.org/abs/2503.22646v1",
    "arxiv_id": "2503.22646v1",
    "authors": [
      "Semaan Douglas Wehbe",
      "Stanley Bak"
    ],
    "published": "2025-03-28T17:32:26+00:00",
    "summary": "Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy."
  },
  {
    "title": "Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels",
    "url": "http://arxiv.org/abs/2503.22634v1",
    "arxiv_id": "2503.22634v1",
    "authors": [
      "Adam Wei",
      "Abhinav Agarwal",
      "Boyuan Chen",
      "Rohan Bosworth",
      "Nicholas Pfaff",
      "Russ Tedrake"
    ],
    "published": "2025-03-28T17:25:57+00:00",
    "summary": "In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \\emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials)."
  },
  {
    "title": "Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments",
    "url": "http://arxiv.org/abs/2503.22595v1",
    "arxiv_id": "2503.22595v1",
    "authors": [
      "S. Aaron McClendon",
      "Vishaal Venkatesh",
      "Juan Morinelli"
    ],
    "published": "2025-03-28T16:42:21+00:00",
    "summary": "In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures."
  },
  {
    "title": "HS-SLAM: Hybrid Representation with Structural Supervision for Improved Dense SLAM",
    "url": "http://arxiv.org/abs/2503.21778v1",
    "arxiv_id": "2503.21778v1",
    "authors": [
      "Ziren Gong",
      "Fabio Tosi",
      "Youmin Zhang",
      "Stefano Mattoccia",
      "Matteo Poggi"
    ],
    "published": "2025-03-27T17:59:54+00:00",
    "summary": "NeRF-based SLAM has recently achieved promising results in tracking and reconstruction. However, existing methods face challenges in providing sufficient scene representation, capturing structural information, and maintaining global consistency in scenes emerging significant movement or being forgotten. To this end, we present HS-SLAM to tackle these problems. To enhance scene representation capacity, we propose a hybrid encoding network that combines the complementary strengths of hash-grid, tri-planes, and one-blob, improving the completeness and smoothness of reconstruction. Additionally, we introduce structural supervision by sampling patches of non-local pixels rather than individual rays to better capture the scene structure. To ensure global consistency, we implement an active global bundle adjustment (BA) to eliminate camera drifts and mitigate accumulative errors. Experimental results demonstrate that HS-SLAM outperforms the baselines in tracking and reconstruction accuracy while maintaining the efficiency required for robotics."
  },
  {
    "title": "Video-R1: Reinforcing Video Reasoning in MLLMs",
    "url": "http://arxiv.org/abs/2503.21776v1",
    "arxiv_id": "2503.21776v1",
    "authors": [
      "Kaituo Feng",
      "Kaixiong Gong",
      "Bohao Li",
      "Zonghao Guo",
      "Yibing Wang",
      "Tianshuo Peng",
      "Benyou Wang",
      "Xiangyu Yue"
    ],
    "published": "2025-03-27T17:59:51+00:00",
    "summary": "Inspired by DeepSeek-R1's success in eliciting reasoning abilities through rule-based reinforcement learning (RL), we introduce Video-R1 as the first attempt to systematically explore the R1 paradigm for eliciting video reasoning within multimodal large language models (MLLMs). However, directly applying RL training with the GRPO algorithm to video reasoning presents two primary challenges: (i) a lack of temporal modeling for video reasoning, and (ii) the scarcity of high-quality video-reasoning data. To address these issues, we first propose the T-GRPO algorithm, which encourages models to utilize temporal information in videos for reasoning. Additionally, instead of relying solely on video data, we incorporate high-quality image-reasoning data into the training process. We have constructed two datasets: Video-R1-COT-165k for SFT cold start and Video-R1-260k for RL training, both comprising image and video data. Experimental results demonstrate that Video-R1 achieves significant improvements on video reasoning benchmarks such as VideoMMMU and VSI-Bench, as well as on general video benchmarks including MVBench and TempCompass, etc. Notably, Video-R1-7B attains a 35.8% accuracy on video spatial reasoning benchmark VSI-bench, surpassing the commercial proprietary model GPT-4o. All codes, models, data are released."
  },
  {
    "title": "Optical control of orbital magnetism in magic angle twisted bilayer graphene",
    "url": "http://arxiv.org/abs/2503.21750v1",
    "arxiv_id": "2503.21750v1",
    "authors": [
      "Eylon Persky",
      "Minhao He",
      "Jiaqi Cai",
      "Takashi Taniguchi",
      "Kenji Watanabe",
      "Xiaodong Xu",
      "Aharon Kapitulnik"
    ],
    "published": "2025-03-27T17:56:23+00:00",
    "summary": "Flat bands in graphene-based moir\\'e structures host a wide range of emerging strongly correlated and topological phenomena. Optically probing and controlling them can reveal important information such as symmetry and dynamics, but have so far been challenging due to the small energy gap compared to optical wavelengths. Here, we report near infrared optical control of orbital magnetism and associated anomalous Hall effects (AHE) in a magic angle twisted bilayer graphene (MATBG) on monolayer WSe$_2$ device. We show that the properties of the AHE, such as hysteresis and amplitude, can be controlled by light near integer moir\\'e fillings, where spontaneous ferromagnetism exists. By modulating the light helicity, we observe periodic modulation of the transverse resistance in a wide range of fillings, indicating light induced orbital magnetization through a large inverse Faraday effect. At the transition between metallic and AHE regimes, we also reveal large and random switching of the Hall resistivity, which are attributed to optical control of percolating cluster of magnetic domains. Our results open the door to optical manipulation of correlation and topology in MATBG and related structures."
  },
  {
    "title": "GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics",
    "url": "http://arxiv.org/abs/2503.21735v1",
    "arxiv_id": "2503.21735v1",
    "authors": [
      "Arsham Gholamzadeh Khoee",
      "Shuai Wang",
      "Yinan Yu",
      "Robert Feldt",
      "Dhasarathy Parthasarathy"
    ],
    "published": "2025-03-27T17:48:32+00:00",
    "summary": "Ensuring the reliability and effectiveness of software release decisions is critical, particularly in safety-critical domains like automotive systems. Precise analysis of release validation data, often presented in tabular form, plays a pivotal role in this process. However, traditional methods that rely on manual analysis of extensive test datasets and validation metrics are prone to delays and high costs. Large Language Models (LLMs) offer a promising alternative but face challenges in analytical reasoning, contextual understanding, handling out-of-scope queries, and processing structured test data consistently; limitations that hinder their direct application in safety-critical scenarios. This paper introduces GateLens, an LLM-based tool for analyzing tabular data in the automotive domain. GateLens translates natural language queries into Relational Algebra (RA) expressions and then generates optimized Python code. It outperforms the baseline system on benchmarking datasets, achieving higher F1 scores and handling complex and ambiguous queries with greater robustness. Ablation studies confirm the critical role of the RA module, with performance dropping sharply when omitted. Industrial evaluations reveal that GateLens reduces analysis time by over 80% while maintaining high accuracy and reliability. As demonstrated by presented results, GateLens achieved high performance without relying on few-shot examples, showcasing strong generalization across various query types from diverse company roles. Insights from deploying GateLens with a partner automotive company offer practical guidance for integrating AI into critical workflows such as release validation. Results show that by automating test result analysis, GateLens enables faster, more informed, and dependable release decisions, and can thus advance software scalability and reliability in automotive systems."
  },
  {
    "title": "ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation",
    "url": "http://arxiv.org/abs/2503.21729v1",
    "arxiv_id": "2503.21729v1",
    "authors": [
      "Zhicheng Lee",
      "Shulin Cao",
      "Jinxin Liu",
      "Jiajie Zhang",
      "Weichuan Liu",
      "Xiaoyin Che",
      "Lei Hou",
      "Juanzi Li"
    ],
    "published": "2025-03-27T17:44:18+00:00",
    "summary": "Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely primarily on parametric knowledge, limiting factual accuracy. While recent works equip reinforcement learning (RL)-based LRMs with retrieval capabilities, they suffer from overthinking and lack robustness in reasoning, reducing their effectiveness in question answering (QA) tasks. To address this, we propose ReaRAG, a factuality-enhanced reasoning model that explores diverse queries without excessive iterations. Our solution includes a novel data construction framework with an upper bound on the reasoning chain length. Specifically, we first leverage an LRM to generate deliberate thinking, then select an action from a predefined action space (Search and Finish). For Search action, a query is executed against the RAG engine, where the result is returned as observation to guide reasoning steps later. This process iterates until a Finish action is chosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach outperforms existing baselines on multi-hop QA. Further analysis highlights its strong reflective ability to recognize errors and refine its reasoning trajectory. Our study enhances LRMs' factuality while effectively integrating robust reasoning for Retrieval-Augmented Generation (RAG)."
  }
]